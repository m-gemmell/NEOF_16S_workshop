[["01-Bacterial_16S_metabarcoding.html", "Bacterial 16S metabarcoding Chapter 1 Introduction", " Bacterial 16S metabarcoding Luca Lenzi and Matthew Gemmell 2021-03-19 Chapter 1 Introduction This practical session aims to introduce you to the analysis of bacterial 16S metabarcoding with QIIME2. The topics covered are: Logging in to our teaching environment "],["02-Background.html", "Chapter 2 Background 2.1 16S rRNA 2.2 ITS and other possible marker genes 2.3 Amplicon sequencing", " Chapter 2 Background One of the most common aims of metagenomic analyses is to quantify the composition and diversity of a community (usually a community of prokaryotes). This can be done in several ways. A common approach is high-throughput amplicon sequencing, usually of a region of the bacterial 16S SSU rRNA gene. Another approach is shotgun metagenomic sequencing, where the whole genomic content of a sample is sequenced. In the first approach, amplicons act as tags identifying the different bacterial species present in the sample, which can be both identified and quantified to describe the composition of the bacterial community (also called metagenetics or metaprofiling). In the second approach, whole genomes, rather than just representative amplicons, are sequenced (shotgun metagenomics). This DNA can be assembled, or the source of the reads can be identified and quantified in a broadly similar way to 16S analysis. In this workshop, we will analyse amplicon sequencing data, obtained by amplification of the variable region 4 of the 16S gene, using primer 515FB-806RB described in http://press.igsb.anl.gov/earthmicrobiome/protocols-and-standards/16s/ (Caporaso et al, 2011). The sequences were obtained from the Illumina MiSeq platform, 2x250bp reads, and the analysis process will be based on the software package QIIME2 (Quantitative Insights Into Microbial Ecology, https://qiime2.org). We will explore the bacterial populations sampled at various locations in the Bioscience building: toilets and corridors from different floors. 2.1 16S rRNA 16S ribosomal RNA is a structural RNA which is a component of the prokaryotic ribosome. Ribosomes are the site of protein synthesis, therefore all prokaryotes have at least a 16S rRNA gene that codes for the 16S ribosomal RNA. The 16S rRNA gene is utilised in reconstructing phylogenies due to its slow rate of evolution, its size and its functional constancy. If the function of 16S rRNA changed then the cell could not synthesise protein correctly and so will not survive. The 16S rRNA gene is ~1,500bp long and is made up of 9 variable regions separated by conserved regions. The variable regions evolve at a faster rate allowing differentiation between bacterial taxa. The conserved regions evolve at a slower rate which allows areas to carry out universal amplification on the gene. The nine variable regions are generally called V1, V2, V3 etc. Secondary structure of 16S rRNA of Esherichia coli (Yarza et al, 2014) 2.2 ITS and other possible marker genes It is very common to perform analysis with marker genes other than 16S, e.g. to study communities of fungi, insects or any other eukaryote species. From the perspective of the bioinformatics analysis, the same overall pipeline can be used for most of the marker genes. ITS (Internal Transcribed Spacer) is a commonly used marker alternative to 16S. QIIME2 can be used to analyse ITS with a few steps and commands required which are unnecessary for 16S rRNA data. In this tutorial, locations will be highlighted where you should consider a pipeline variation if you are using ITS. In general, we recommend searching the literature so you can be aware of the state-of-the-art methods for the analysis of your marker of interest. 2.3 Amplicon sequencing The use of high-throughput amplicon-sequencing has proven to be powerful and accurate for microbial community analysis. It is currently the preferred choice used to investigate biological communities (bacterial or eukaryotic) in many samples and conditions. Some of the reasons for this methods popularity are: It is relatively easy to perform. It can be performed with many samples. It is relatively fast and cheap. On the negative side, there are many steps which may potentially introduce biases in the final result: Experimental design, sampling, storage and DNA extraction methods are known to potentially reduce the initial bacterial population processed and sequenced. Any reagent used may add exogenous bacterial population to the samples (potentially contaminating or changing the initial bacterial amount). Several papers discuss how the PCR protocol used for the amplification of the DNA material may affect the final results (such as the creation of chimeric sequences or by preferentially amplifying some bacterial). The choice of sequencing platform may result in the identification of different species in the same samples by having its own characteristic error-profile. From the bioinformatics perspective, the length of the sequences, and the pipeline used for the analysis are also able to add variability to the final results. The identification of the species in the samples can be affected by the quality and completeness of the database used for the analysis. Additionally, it may become less precise at lower taxonomy levels such as genus and species (Hugerth and Andersson, 2017). All these aspects need to be taken into account in the discussion of the results. Above shows a representation of amplicon sequencing. Different species are shown as different colours, with the indication of which species are in the site under investigation. Some species may be excluded from the sequencing because they are: Missed by the sampling methods (purple dots) Lost during the sample preparation (outside green square) Lost by the extraction technique (outside green square) Not amplified in the PCR step (outside pink square) Representation of the number of sequences obtained for a sample, showing that increasing the number of sequences increases the probability to retrieve low-abundant species in the samples. The main purpose for this analysis is to infer the number and type of species in the initial sampling site by the abundance of the sequences obtained by the sequencing experiment. In order to do this effectively, the use of mock communities and negative controls is strongly suggested to evaluate the effect of any possibly introduced bias. Additionally, normalisation of the data is absolutely necessary to compare the diversity between sample groups. "],["03-Intro_to_qiime2.html", "Chapter 3 Introduction to QIIME2 3.1 Artifacts 3.2 Workflow 3.3 Prepare the sequence dataset 3.4 Amplicon Sequence Variants identification 3.5 Assign a taxonomic classification to each ASV 3.6 Build phylogenetic tree 3.7 Data normalisation 3.8 Alpha-diversity 3.9 Beta-diversity 3.10 Differentially Abundant Analysis", " Chapter 3 Introduction to QIIME2 Since January 2018, the QIIME project released the QIIME2 (qiime2.org, Bolyen et al., 2018) pipeline to analyse amplicon sequencing data. The QIIME1 scripts, in its latest release QIIME1.9.1, are still available (and their methods are still valid) however the suggestion is to use QIIME2, as QIIME1 is no longer supported. In the following practical we will use the QIIME2 released on January 2019 (given the active development on the tool this is not be the most recent release at the time of this workshop but fine for this workshop). To install QIIME2, please refer to its instruction page: https://docs.qiime2.org/2021.2/install/ 3.1 Artifacts The QIIME2 pipeline produces and uses artifact files. These contain data and metadata and may be of two types: result or visualisation. Result files (.qza): This file type contains the results of a method, which accepts other artifacts and specific settings as input, in order to apply a procedure creating a new artifact (e.g. loading sequences, error correction, alpha- or beta-diversity). Visualisation files (.qzv): This file type contains the results of a specific procedure to obtain an object that can only be used to visualize the results. These files can be loaded into the following web-site https://view.qiime2.org, where the interactive visualisations can be viewed. Please note that only chrome and Firefox are supported by this QIIME2 website. 3.2 Workflow The steps for the analysis are listed below, mainly taken from https://docs.qiime2.org/2019.1/tutorials/. Representation of the step proposed for the analysis (http://compbio.ucsd.edu/wp-content/uploads/2016/10/20170712_microbiome_16s_tutorial_non-interactive.pdf) Prepare the sequence dataset Remove PCR primers Amplicon Sequence Variants identification Assign a taxonomic classification to each AVS Train naive-classifier for assignment Taxonomy assignment of the identified ASVs Make a phylogeny tree for the ASVs Alignment of the identified ASV Masking low quality alignment Creating the un-rooted phylogenetic tree Creating the rooted phylogenetic tree Summarise the taxonomy data for each sample and plot results Estimate and plot alpha diversity Estimate and plot beta diversity Differential abundance analysis 3.3 Prepare the sequence dataset The read set you will be using in this tutorial will be a raw dataset. It still includes low quality sequences, Illumina sequencing adapters as well as PCR primers. Before proceeding with the analysis, it is a good strategy to investigate the quality of the sequences. The PCR primers used for the amplification may have degenerate positions (required for annealing to the large variety of species in the samples). This adds random variability outside the target region. These unknown sequences may affect the subsequent taxonomy identification as well as the error-correction step. We will use Cutadapt to remove the PCR primers before any other step. If the analysis is based on a marker gene different than 16S, other quality trimming may be required. In the case of the ITS marker gene, the common practice is to trim off the conserved regions (SSU, 5.8S or LSU) that may be contained in the final amplicon. The ITSxpress software (Rivers et al., 2018) is designed for this specific task and it is available as a QIIME2 plug-in, though it requires specific installation steps because it is not installed with the basic (core) installation process. It could be found among the list of third-party QIIME2 available plug-ins (https://library.qiime2.org/plugins/ ). 3.4 Amplicon Sequence Variants identification The key element of this type of metagenomic analysis is the identification of the different rRNA variants in the sample. 3.4.1 OTUs The most used procedure to identify OTUs (Operational Taxonomic Units) is through the clustering of reads into groups that are sufficiently similar to one another. These grouped reads are likely to come from the same rRNA gene, genome or taxa group. The identified OTUs are a feature of the sequence dataset, heavily dependent on the similarity level used for OTU identification. The most commonly used threshold is 3% dissimilarity (i.e 97% similarity) to group reads into species OTUS. Therefore, de novo OTUs identified in two different data sets cannot be compared. There is no single perfect tool for this step; but a few of the most widely used are: UCLUST (the default used by QIIME1.9.1) VSEARCH CD-Hit SWARM (if you work with QIIME1.9.1 we recommend using SWARM for this step) The number of reads in each OTU should reflect the number of copies of the gene in the sample, thus providing a quantitative measure of diversity. 3.4.2 ASVs There are now many bioinformatics methods to resolve amplicon sequence variants (AVS) from Illumina data. These methods do not impose the arbitrary dissimilarity thresholds that define molecular OTUs. The two methods available in QIIME2 are DADA2 and deblur. ASV methods infer the biological sequences in the sample prior to the introduction of amplification and sequencing errors, and distinguish sequence variants differing by as little as one nucleotide. The methods use a de novo process in which biological sequences are discriminated from errors on the basis of, in part, the expectation that biological sequences are more likely to be repeatedly observed than error-containing sequences. Unlike de novo OTUs, ASVs are consistent labels because ASVs represent a biological reality that exists outside of the data being analysed: the DNA sequence of the assayed organism. Thus, ASVs inferred independently from different studies or different samples can be validly compared. The following picture (http://ju.outofmemory.cn/entry/332219) shows how DADA2 (an ASV method) and OTU processes compare each other. This shows how the canonical creation of OTUs creation by clustering may lead to an overestimation of the size of the OTUs due to the presence of errors, from either PCR or sequencing. Much of the work involved in analysis of amplicon-based metagenomic data is that of separating true variants from errors introduced by sequencing. These errors include miscalling of nucleotides and the generation of chimeric sequences. For sequencing purposes, an aliquot of PhiX phage DNA is added to each sample before sequencing, both DADA2 and deblur include a step aimed to exclude any PhiX associated reads. To remove PCR chimeric artefacts, a further filter step is applied by both. QIIME 2 Authors suggest using DADA2 for read pairs and deblur for already paired (stitched/joined) sequences. Please note that it is good practice to remove/trim out sequences containing Ns before the error correction step. It is not suggested to denoise with DADA2 samples from different sequencing lanes, because each lane may introduce different sequencing bias. It is possible to collate the denoised abundance tables and representative sequences afterward, recording the sequencing lane for each sample in a specific metadata column. The deblur denoise tool may be used in this case because it should be less sensitive to these possible biases, however it is good practice to keep the lane of origin in the metadata (with the second benefit that deblur is also faster than DADA2). 3.5 Assign a taxonomic classification to each ASV The sequence of each ASV is compared with the selected database, to identify the most likely taxonomy for each ASV. Unfortunately different parts of the taxonomic identification step may lead to different results for the same ASV. Different databases may result in different taxonomic classification for the same ASV. The choice of tool used for taxonomic assignment may also impact the results in a similar way. The current version of QIIME2 allows you to select from either the Scikit-learn classifier (a classifier which applies a machine learning approach and therefore needs training before use) or BLAST+ and VSEARCH (for a global alignment approach followed by a last common ancestor search) for this step. In the practical we will use Scikit-learn (similar to the RDP tool widely used so far). It has been shown that (at least in the case of 16S analysis) taxonomic classification accuracy improves when the classifier is trained with sequences derived from the amplicon region only (Werner et al., 2012). 3.6 Build phylogenetic tree To include phylogenetic diversity metrics in the diversity analysis, such as UniFrac distance metric, the construction of a phylogenetic tree for the identified AVS previously identified is required. QIIME2 supports MAFFT for the alignment and MASK to mask the alignment sections that are not phylogenetically informative. Unrooted and rooted trees may be created. For some marker genes it is not possible to build phylogenetic tree (ITS is among these), and it is therefore important to know the properties of the marker in use. Consequently, it is not possible to use any diversity metrics that requires the phylogenetic distance as input. 3.7 Data normalisation Any further analyses to compare the identified ASVs among sample groups (either alpha- or beta-diversity or differential abundance) should account for the features of the abundance table that can cause erroneous results (Weiss et al., 2017). These features are: The microbial community in each sample may be represented by different numbers of sequences (i.e. sequencing depth for each sample). The abundance table is usually sparse. That is, most of the ASVs are present only in a few samples and therefore the abundance table contains many 0 values (it is also possible that a particular species is present in a sample but below the detection limit of the methods). The total number of sequences obtained reflect the relative abundance of species sequenced rather that the absolute abundance of the species present in the sample (this is commonly referred as compositional nature of the data). The relative abundances for the taxa are therefore not independent as in the underlying assumption of many frequently used statistical methods (Gloor et al., 2017). A normalisation step for the data is required to mitigate these effects and to allow an easier data interpretation. The most used normalisation methods are: Normalisation by rarefaction. This is performed by reducing all the samples at the same sequence count, by random sub-sampling of the sequences. This method may lead to a potential reduction of the species in your dataset (alpha-diversity) and to the exclusion of any samples not reaching the selected total count per sample. DESeq method (borrowed from transcriptomic research) Scaling the abundance table by a fixed value or proportion. Applying a log-ratio transformation proposed by Aitchinson (1982) in analogy of compositional dataset. This is aimed to convert the abundance data into scales on which it is possible to apply conventional statistical procedures. Methods b-d convert the abundance table in a normalised-abundance table with different strength and pitfalls, therefore they can affect results for beta-diversity and differentially abundant analysis. These normalisation methods were compared by Weiss and colleagues (2017), but their simulations show that different methods may result in different sensitivity and different false discovery rates. In this tutorial, following the QIIME2 current tutorial, we will apply the following normalisation methods: The rarefaction method, in the context of the alpha- and beta-diversity analysis. The centered log-ratio transformation (clr-transformation) method, in the context of the differential abundance analysis. 3.8 Alpha-diversity Alpha-diversity is used to measure the diversity within a sample. It is calculated as a value for each sample. Different metrics were developed to calculate diversity in different ways. It combines richness (a measure of the number of species in the sample) and evenness (a measure of the relative abundance of different species that make up the richness of that sample). Alpha diversity measures cannot be compared unless they have been normalised for the difference in sequencing depth between samples. The QIIME2 release we will use supports the following alpha-diversity measures, amongst others: Chao1, Shannon, Simpson, Simpson evenness, Faiths Phylogenetic Diversity (the only one considering the phylogenetic relationships among the ASVs). The alpha-diversity metric used for the analysis must be chosen carefully, considering its mathematical definition in relation of the behaviour of the tools used for the previous steps. An important point to consider is whether the chosen metric uses ASVs with only 1 sequence (singletons) to perform some estimation on the dataset or not. The Chao1, as one example for this, uses the number of singletons in the dataset to infer the total number of singletons in the population. However, the DADA2 denoising step excludes singletons from the final output, making Chao1 measures not applicable to its resulting abundance tables. A second consideration regards if the phylogenetic tree is available enabling the use of the Faiths Phylogenetic Diversity metric, for markers such as ITS this metric would not be possible. 3.9 Beta-diversity Beta-diversity is a term for the comparison of samples to each other. It is also referred as beta-diversity ordination, because it uses one (or more) technique/s to arrange samples along axes on the basis of their composition to highlight the differences. The current QIIME2 release supports only the Principal Coordinates Analysis (PCoA) method to investigate beta-diversity (within the old QIIME1 pipeline you could perform nMDS as well). The starting point of the analysis is a dissimilarity matrix, which is used to perform a Principal Component Analysis (PCA) to reduce the dimension for display purpose. The axes obtained from the PCA analysis are then compared with the categories in the metadata file to identify patterns. A few of the commonly used beta diversity metrics supported by QIIME2 are: Jaccard: A non-phylogeny based method that takes into account only presence/absence of a ASVs to measure the distance between two samples. Bray-Curtis: A non-phylogeny based method that takes into account the number of ASVs as well as their abundance while measuring the distance between two samples. Un-weighted UniFrac: Uses the presence and absence of ASVs and phylogenies. Weighted UniFrac: Uses the abundance information of ASVs and phylogenies. As discussed for the alpha-diversity, before proceeding with the beta-diversity analysis the raw abundance table for the identified ASVs needs to be normalised, to this QIIME2 suggests using the rarefaction methods, in particular at the same rarefaction threshold used for the alpha diversity. The choice of the beta-diversity distance metric to use will strongly affect the results, it therefore common practice to compare the results obtained with different metrics. Again, not all the metrics may be applicable to all the marker genes, for example the UniFrac distances could not be easily used in the case of ITS, because ITS sequences are quite difficult to align onto phylogenetic trees. 3.10 Differentially Abundant Analysis The identification of taxa that are differentially abundant across experimental conditions may be an important result for many types of metagenetics analyses. This step is extremely dependent on the normalization methods used to compare the samples: using different normalisation methods may lead to different results (consequently this is another active area of research). QIIME2 supports two normalisation methods to investigate differentially abundant taxa across experimental conditions: ANCOM (Mandal et al., 2015) and GNEISS (Morton et al, 2017). Both methods are based on the conversion of the abundance values using the clr-transformation method prior to any comparison. Because the conversion is based on a logarithmic transformation, all the value in the abundance table will be increased by 1 to avoid 0 counts (pseudo-counts). These methods may therefore artificially increase the alpha-diversity for the samples as well as decrease the beta-diversity distances in the dataset. In this analysis we will use the ANCOM method following the current QIIME2 tutorial. This method computes the log-ratio for every possible pair of the identified taxa (using the mean group values for the clr-transformed abundance) and reports how many times the hypothesis H 0 = X is not differentially abundant is rejected for each taxa X. That is the W statistics, the higher this value is the more significant the ASV/taxa X is differentially abundant between the tested groups. This test assumes that a large number of ASVs did not change in abundances between groups. If, in the results, more than 25% of the ASVs changes in the examined contrasts, the underlying hypothesis for the ANCOM test may be not fulfilled, and there is the chance that the results may be misleading. Examples of questions to answer - Are there differences in taxa at various levels of taxonomy? - What are the most abundant ASVs (or species)? - What are the rare ASVs present (either real or still retained sequencing error)? - Where are the rare ASVs present (if not sequencing error)? - ASVs correlation: is there a correlation between ASVs and other attributes of samples, like pH or other environmental conditions? "],["04-Cluster_Introduction.html", "Chapter 4 Cluster Introduction 4.1 Logon instructions 4.2 The Terminal Window", " Chapter 4 Cluster Introduction 4.1 Logon instructions For this workshop we will be using Virtual Network Computing (VNC). Connect to the VNC with a browser by using the webVNC link you were sent. You will now be in a logged-in Linux VNC desktop with two terminals. You will see something as below (there may be only one terminal which is fine). If you do not see something similar please ask for assistance. If the VNC is taking up too much/little space of your browser you can use the zoom of your browser to adjust the size. Ensure you can see one whole terminal. These instructions will not work outside of this workshop. If you would like to install your own Linux OS on your desktop or laptop we would recommend Ubuntu. The following link is a guide to install Ubuntu: https://www.ubuntu.com/download/desktop/install-ubuntu-desktop. If you use a USB you need to create a bootable USB stick. The following link will assist: https://www.ubuntu.com/download/desktop/create-a-usb-stick-on-windows 4.2 The Terminal Window In our case the terminal window looks like the picture below. We are using the terminal window as our shell to interpret our commands to the kernel. Depending on your system and preferences it may look different. Already there is useful information for us on the terminal window. nsc006: This is the login name, also known as the username. In this case nsc006 is a demonstrators account. Your screen should show a different account name which will be your username for the Linux machine/cluster you are logged into. gauss03: This is the machine name the user is logged into. ~: This represents the current directory of the user, or the directory a command was run in. In the Linux OS and others ~ is a shortcut to the users home directory. Everything after the $ is where commands are typed into the terminal. This is also referred to as the command line. To open a new terminal window, right click on the main screen, choose Applications -&gt; Shell -&gt; bash "],["05-Linux_quick_user_guide.html", "Chapter 5 Linux quick user guide 5.1 Accessing the data and navigating the command line.", " Chapter 5 Linux quick user guide In the following parts of the practical exercise, descriptions of commands will be marked by hash character, #, these lines should not be typed in the terminal. e.g. # description; Commands directed to the bash terminal will be in red. e.g. cat filename Run the commands one after the other, from the command line. When a commands length exceeds the width of the line available in the paragraph, the convention used in this document is to represent the incompleteness of the command in the first line by ending it with a \\ sign. You may choose to split the command onto more than one line using this method in the shell or you may type the second line of the command straight after the first. In the former case, after typing the \\ and pressing ENTER, the prompt will show a &gt; sign indicating it is waiting for more command. This prompt &gt; is NOT reported in the command you have to type, so in any case this document showing a command line starting with the &gt; sign please be careful to type it. 5.1 Accessing the data and navigating the command line. In Unix, everything works via commands on the command line. Also, the Unix environment consists of directories which may contain other directories and/or files. At any one time you are in a directory, which is within another directory and so on, and there are directories below you, which you can move into. When you type pwd, you see the full path to your location, or working directory (e.g. /pub39/tea/luca/Metagenetics_2019). The directories are separated by /. The initial / is the root directory (the directory that contains everything else). When you first log in, you are in your home, the directory containing all the files and directories that you create. To make a directory, move into it, see where you are, what else is there and move up out of it, try these commands. mkdir adirectory cd adirectory pwd ls cd .. ls rm r adirectory Here, cd changes your directory (.. means jump up a level) and ls lists the files and directories you can see (the -l option gives more information about each file/dir). You can delete a file or directory using the rm command, adding the -r option for a directory. Use these until you are comfortable navigating around. Now you need to obtain the raw data you will be analysing in this workshop. Create a main directory for the workshop and copy the directory of workshop data from its location (/pub39/tea/luca/Metagenetics_2019/RawReads) to your directory (.) using the cp command. The -r option allows you to copy an entire directory. cd ~ mkdir Metagenetics cp -r ~luca/Metagenetics_2019/RawReads ./Metagenetics/RawReads cp ~luca/Metagenetics_2019/PairedEndFastqManifestPhred33.csv \\ ./Metagenetics cp ~luca/Metagenetics_2019/metadata.file.txt \\ ./Metagenetics Take a look at the data files ls -l Metagenetics/RawReads Now navigate into the directory, where you will do the analyses cd Metagenetics Now you will explore the data you are going to analyse. It is important to get a feel for the data and how it should and shouldnt look. If the data were generated by Illumina (HiSeq or MiSeq), they will be in fastq format, a text format that can be easily viewed. If the data are Illumina (HiSeq or MiSeq) and were generated by the CGR, these are the raw files which are already demutliplexed using the software CASAVA but were NOT postprocessed to remove adapter sequences and low-quality bases (as per standard protocol prior to most analysis). If your data is paired-end (MiSeq data will be), then each sample has two data files. E.g.: 1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz 1K1E_AAGAGGCA-GTAAGGAG_L001_R2_001.fastq.gz In this case, the names denote sample 1, barcode AAGAGGCA-GTAAGGAG, lane 1 (L001), forward reads (R1) or reverse reads (R2), file 1 (001). Files are in fastq format and are often compressed with gzip (.gz). Files are typically very large. Hence you must be careful to handle them in the right way. They are usually too large to simply open in a text editor, so dont try. Instead, you should use Unix commands and scripts to manipulate them. Ensure the Illumina reads are in fastq format by having a look. To view the top of the file, use the head command (tail is an equivalent command which lets you view the end of a file, while less and more allow you to scroll through the file). In here we will use the zless command which is able to open files compressed with gzip. zless RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz Notice that each read is represented by 4 lines: The first line is the read identifier. The second line is the sequence, and the fourth line is the quality score for this sequence. Qualities are in ASCII codes (in which a symbol represents a number: in this case the quality of the basecall). Note that the barcode sequence is displayed in the read header (but it may contain Ns). At this stage, you can get some information about your data. For instance, how many reads do you have? We can use the grep command to find every match to the pattern ^+$ (^=start of line, $=end of line, so match a line with a single + on it). There is only one line like this per read so the number of matches = the number of reads. The -c option makes grep return the count of the number of matches (rather than the matches themselves). zgrep -c ^+$ 1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz You should obtain: ~/Metagenomics/RawReads$ zgrep -c ^+$1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz #result = 53731 "],["06-QIIME2_analysis_workflow.html", "Chapter 6 QIIME2 analysis workflow 6.1 Workflow", " Chapter 6 QIIME2 analysis workflow 6.1 Workflow The QIIME2 analysis workflow comprises of nine steps: Import sequences into QIIME2 artifact Trim the PCR primer sequences De-novo amplicon sequence variants identifications Assign a taxonomic classification to each ASV Make a phylogenetic tree of the identified ASVs Sequencing depth evaluation: rarefaction plot Sequencing controls evaluation: beta-diversity without normalisation Diversity analysis: alpha and beta Differential abundance analysis of ASVs across different conditions "],["07-Import_sequences_into_QIIME2.html", "Chapter 7 Import sequences into QIIME2", " Chapter 7 Import sequences into QIIME2 The input files for the QIIME2 pipeline are two text files, (a) the manifest file and (b) the metadata.file.txt. The manifest file is a file listing the absolute path for the sequence files. The head of the manifest file we are going to use, is: head n 7 PairedEndFastqManifestPhred33.csv sample-id,absolute-filepath,direction 1K1E,/pub39/tea/luca/Metagenetics_2019/RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz,forward 1K1E,/pub39/tea/luca/Metagenetics_2019/RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R2_001.fastq.gz,reverse 1K1MB,/pub39/tea/luca/Metagenetics_2019/RawReads/1K1MB_CGAGGCTG-GTAAGGAG_L001_R1_001.fastq.gz,forward 1K1MB,/pub39/tea/luca/Metagenetics_2019/RawReads/1K1MB_CGAGGCTG-GTAAGGAG_L001_R2_001.fastq.gz,reverse 1K2E,/pub39/tea/luca/Metagenetics_2019/RawReads/1K2E_AGGCAGAA-GTAAGGAG_L001_R1_001.fastq.gz,forward 1K2E,/pub39/tea/luca/Metagenetics_2019/RawReads/1K2E_AGGCAGAA-GTAAGGAG_L001_R2_001.fastq.gz,reverse In the manifest, each filed is separated by a comma , character. The first column represents the identifier for the sample that will be used everywhere in the following analysis. The second column is the full path for the sequence file, and the third column is the orientation for the sequences in the file. If you wish to perform the pairing within DADA2, each sample will be represented by two lines: for R1 and R2. Please note, before starting the import step you have to edit the manifest file and the paths for the sequence files to match the actual path from your home folder. An example /pub39/tea/luca/Metagenetics_2019/RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz Should become (where XXX is equal to the number in your username): /pub39/tea/nscXXX/Metagenetics/RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz The metadata.file.txt, is a text table (each field separated by a TAB character) listing all the information for each sample. less metadata.file.txt Results: sample-id BarcodeSequence Floor Location Place #q2:types categorical numeric categorical categorical K2 CTCTCTAC-ACTGCATA 1 StudentCorridor Entrance T CAGAGAGG-ACTGCATA 1 StudentHome Entrance 1K1E AAGAGGCA-GTAAGGAG 1 Corridor Entrance 1K1MB CGAGGCTG-GTAAGGAG 1 Corridor MainBuilding 1K2E AGGCAGAA-GTAAGGAG 1 Corridor Entrance 1K2M CGTACTAG-GTAAGGAG 1 Corridor MainBuilding In this file, you may want to include as much information as you can on the data, please note that if a column contains only numbers QIIME2 scripts will consider it as numerical, such as days, depths or weights (as opposed to categorical such as sex, location or barcodes). To force QIIME2 to interpret the column as you want, it is possible to specify the type of value in the second line of the file, as in this example. To run QIIME2s commands we first need to activate it: source ~luca/Metagenetics_2019/qiime2_env.sh That will be the same as running the command source activate qiime2-2019.1 in your own installation. Next run: source tab-qiime Please, remember to run the 2 above commands on any new terminal window (or bash shell) you are going to open for the practical. When running the commands/scripts marked in red, please ensure you are in Metagenetics directory. First, we will load all the read pairs into an artifact. qiime tools import --type &#39;SampleData[PairedEndSequencesWithQuality]&#39; \\ --input-path PairedEndFastqManifestPhred33.csv \\ --output-path paired-end-demux.qza \\ --input-format PairedEndFastqManifestPhred33 This will use the information contained in the manifest file to create the paired-end-demux.qza, the name refers to the fact that samples in here are already demultiplexed (will takes approx. 1 min). To visualise the samples loaded, the following command will create a visualisation artifact associated to the main sample artifact (approx. 30 sec). qiime demux summarize --i-data paired-end-demux.qza \\ --o-visualization paired-end-demux.qzv This next step is important! Make sure to open a new terminal and open chrome in it. For the rest of the day keep this terminal and chrome open (To open a new terminal look at page 11). Opening and closing chrome multiple times has proven to cause issues in past workshops. To open the browser chrome, run: chrome.sh Then: Type the following web-site: view.qiime2.org Click on Drag and drop or click here panel You can browse now to find and select the file paired-end-demux.qzv Questions: Are the sequences evenly distributed across samples? Which sample has the lowest number of sequences? Is there any sample with a low final number of sequences? Are there any samples that can be excluded? What is the average sequence count per sample? How is the overall quality for the sequences? "],["08-Trim_PCR_sequences.html", "Chapter 8 Trim the PCR primer sequences", " Chapter 8 Trim the PCR primer sequences Reads are paired-end (R1 and R2) and may overlap in the middle, depending on the size of the sequenced amplicon and the size of the paired reads. Our sequencing data is of the 16S rRNA V4 region (length: ~250bp). Therefore, our 250bp x 2 paired end reads should overlap. If R1 and R2 overlap, we can use this to reconstruct the V4 region by aligning and merging the forward and reverse reads of each pair. We will use the cutadapt (Martin, 2011) tool to remove the PCR primer sequences from R1 and R2 (approx. 5 min). qiime cutadapt trim-paired --i-demultiplexed-sequences paired-end-demux.qza # Forward primer --p-front-f NNNNNGTGCCAGCMGCCGCGGTAA \\ # Reverse primer --p-front-r GGACTACHVGGGTWTCTAAT \\ --o-trimmed-sequences paired-end-demux.trim.qza To visualise the trimmed samples, the following command will create a visualisation artifact associated with the main sample artefact (approx. 2 mins). qiime demux summarize --i-data paired-end-demux.trim.qza \\ --o-visualization paired-end-demux.trim.qzv If you are working with ITS region, to trim off the conserved regions from the sequences you can use the q2-itxpress plug in. To install and use this plug-in, please see its specific manual: https://library.qiime2.org/plugins/q2-itsxpress/8/ Depending on your experimental design, you may have to perform the trimming of the PCR primer, sequencing adapters and/or using the conserved region using the itsxpress trimming only. Questions: Are the sequences evenly distributed across samples? Which sample has the lowest number of sequences? Are there any samples that can be excluded? What is the average sequence count per sample? How is the oveerall quality for the sequences? Which truncating lengths would you chose for R1 and R2? "],["09-ASV_identification.html", "Chapter 9 De-novo amplicon sequence variants identification", " Chapter 9 De-novo amplicon sequence variants identification We will use DADA2 to identify the amplicon sequence variants (ASVs) among all the samples. To perform the variant sequence identification step with DADA2, the command is (dont run this command, see below command): qiime dada2 denoise-paired \\ --i-demultiplexed-seqs paired-end-demux.trim.qza \\ # Truncates R1 sequences after the 220 nt length --p-trunc-len-f 220 \\ # Truncates R2 sequences after the 220 nt length --p-trunc-len-r 220 \\ # Object containing the identified variants --o-representative-sequences rep-seqs-dada2.qza \\ # Object containing abundance table for the identified variants --o-table table-dada2.qza \\ --o-denoising-stats dada2-stats.qza \\ --verbose This step will take a long time, so stop the command (ctrl+c) and copy the final output files, which have been previously made, to your current directory: cp ~luca/Metagenetics_2019/table-dada2.qza . cp ~luca/Metagenetics_2019/rep-seqs-dada2.qza . cp ~luca/Metagenetics_2019/dada2-stats.qza . The rep-seqs-dada2.qza artifact contains the identified sequence variants and the tabledada2.qza artifact contains their abundance data. The dada2-stats.qza artifact summarises the statistics after the main denoising steps. This may be one of the longest steps of the whole pipeline. The running time is proportional to the complexity of the sequences (how many ASVs are in the dataset) and to the quality of the sequences (how many errors are present). If in your one of your future projects this step is taking too long, you may try to use deblur to de-noise your data (after joining the reads with vsearch), which is generally faster. In the case of a marker gene with very variable amplicon sequence length, as in the case of ITS amplicon sequencing, a possible alternative denoising strategy is to disable the filtering by truncation length using the options: --p-trunc-len-f 0 and --p-trunc-len-r 0. To exclude the low quality tails the --p-trunc-q 20 option is now required, this option will trim all the sequences after the first base with quality below 20 (this may be very stringent, so you may want to try with lower values as well). A further possibility may be to use only either the forward or reverse read file, for this the qiime dada2 denoise-single should be use instead the above dada2 command. To visualise the result, run: qiime feature-table summarize --i-table table-dada2.qza \\ --o-visualization table-dada2.qzv \\ --m-sample-metadata-file metadata.file.txt And load the obtained table-dada2.qzv into the view.qiime2.org website. qiime metadata tabulate --m-input dada2-stats.qza \\ --o-visualization dada2-stats.qzv And load the obtained dada2-stats.qzv into the view.qiime2.org website. Questions: In which denoising step were most of the sequences lost? Are enough sequences left to proceed with the analysis? How many variants (also called features) have been identified? How are the variants distributed across samples? How many sequences are rare (represented in few samples or in low number)? "],["10-Taxonomic_assignment.html", "Chapter 10 Assign a taxonomic classification to each amplicon sequence variant", " Chapter 10 Assign a taxonomic classification to each amplicon sequence variant Now that we have defined the sequence variants in the samples, we can assign taxonomic labels to them. Here, we use the sk-learn classifier to assign taxonomy based on the Greengenes database (DeSantis et al., 2006). Greengenes is a database containing quality-controlled microbial sequence data. Greengenes 16S rDNA sequences come from a large number of species which have been formatted for use in QIIME, by clustering the sequences at a given level of similarity (here, 99%). As for OTU-picking, the more stringent the similarity threshold, the more fine-grained the taxonomic designation (i.e. there are more Greengenes OTUs defined to the species level at 99% than at 97% similarity). The classifier maps the variant sequences, defined above, to OTU representative sequences from the Greengenes set. First, we need to import the Greengenes data into QIIME2 artifact objects. qiime tools import \\ --input-path /pub39/tea/luca/Metagenetics_2019/db/gg_13_8_otus/rep_set/99_otus.fasta \\ --output-path gg-13-8.99_otus.qza \\ --type &#39;FeatureData[Sequence]&#39; qiime tools import \\ --input-path /pub39/tea/luca/Metagenetics_2019/db/gg_13_8_otus/taxonomy/99_otu_taxonomy.txt \\ --output-path gg-13-8.99.taxa.qza \\ --input-format HeaderlessTSVTaxonomyFormat \\ --type &#39;FeatureData[Taxonomy]&#39; These steps will create two objects containing the sequences and their taxonomy, respectively, and should finish in less than 2 mins. The classifier tool we are going to use requires a training step to reach its optimum performance. The training is performed on a read set extracted from Greengenes representative sequences, including only the amplified region of interest. Note: Do not run the below command for this tutorial, see below command) qiime feature-classifier extract-reads \\ --i-sequences gg-13-8.99_otus.qza \\ --p-f-primer NNNNNGTGCCAGCMGCCGCGGTAA \\ --p-r-primer GGACTACHVGGGTWTCTAAT \\ # Creating reads of 250 bp as in our case --p-trunc-len 250 \\ --o-reads gg-13-8.99.ref.seqs.qza Given that this step may require more than 14h to finish, we wont be able to run on this occasion. Copy over premade result with the following command: cp /pub39/tea/luca/Metagenetics_2019/gg-13-8.99.ref.seqs.qza . To train the sk-learn classifier on this set of reads (approx. 25 mins): qiime feature-classifier fit-classifier-naive-bayes \\ --i-reference-reads gg-13-8.99.ref.seqs.qza \\ --i-reference-taxonomy gg-13-8.99.taxa.qza \\ --o-classifier classifier.trained.qza The command for the taxonomy assignment is (approx. 5 min): qiime feature-classifier classify-sklearn \\ --i-classifier classifier.trained.qza \\ # Default value for confidence --p-confidence 0.7 \\ --i-reads rep-seqs-dada2.qza \\ --o-classification taxonomy.sklearn.qza To visualise the taxonomy-abundance bar-chart obtained, run (approx. 1 min): qiime taxa barplot --i-table table-dada2.qza \\ --i-taxonomy taxonomy.sklearn.qza \\ --m-metadata-file metadata.file.txt \\ --o-visualization taxa-bar-plots.dada2.qzv Once you have loaded the file in the browser, you may specify the taxonomic level to look at, as well as a few sorting and colouring options. Questions: What is the most abundant taxon, at level 5, in the dataset? How do the samples compare to each other? If you have sequenced any samples with known composition (e.g. mock community), now is the time to see if they behave as expected, you may want to change some step and/or settings of what you have done so far if the composition does not match what you expect. For example, change the de-noising tool or apply more quality filters to further improve the quality of the sequence under examination. "],["11-Phylogentic_tree.html", "Chapter 11 Make a phylogenetic tree of the identified ASVs", " Chapter 11 Make a phylogenetic tree of the identified ASVs To obtain the phylogenetic tree the steps are: Alignment of the sequence variants with MAFFT Masking out the uninformative sequences with MASK Creation of the un-rooted tree with FASTTREE Creation of the rooted tree The rooted tree will be used to compute phylogenetical aware alpha- and beta-diversity metrics such as Faiths Phylogenetical Distance (Faiths PD) and UniFrac distances, for any marker for which this is possible (therefore excluding ITS among others). The commands are the following: qiime alignment mafft --i-sequences rep-seqs-dada2.qza \\ --o-alignment aligned-rep-seqs.qza qiime alignment mask --i-alignment aligned-rep-seqs.qza \\ --o-masked-alignment masked-aligned-rep-seqs.qza qiime phylogeny fasttree --i-alignment masked-aligned-rep-seqs.qza \\ --o-tree unrooted-tree.qza qiime phylogeny midpoint-root --i-tree unrooted-tree.qza \\ --o-rooted-tree rooted-tree.qza All these steps should finish in approx. 3 min, the final artifact for later use is rooted-tree.qza "],["12-Rarefaction.html", "Chapter 12 Sequencing depth evaluation: rarefaction plot", " Chapter 12 Sequencing depth evaluation: rarefaction plot The diversity detected depends, to an extent, on the sampling depth (i.e. an incompletely sampled community will appear less diverse than a fully sampled community). Therefore, to compare the diversity among samples of different sizes, we need to account for this. We can do this by rarefaction, or re-sampling, from the data. Equally sized subsamples are directly comparable among different samples. In addition, if we sample progressively smaller subsamples from a sample, we draw a curve of estimated alpha diversity. The shape of this curve is informative. If the curve plateaus, then increased sampling depth will not increase the estimate of alpha diversity (the community is fully sampled). Example rarefaction curve: We can see that Series 1 plateaus at ~7,000 sequences and Series 3 plateaus at ~18,000 sequences whilst Series 2 has not started to plateau. Given an abundance table (and a phylogenetic tree for calculating phylogenetic distance), we can plot the rarefaction curve using different alpha-diversity metrics. Here, we will use diversity metircs (observed variants, Simpson, Shannon, Faiths PD) as well as an evenness metric (Simpson evenness). You may want to exclude --p-metrics faith_pd for markers such as ITS. qiime diversity alpha-rarefaction --i-table table-dada2.qza \\ --i-phylogeny rooted-tree.qza \\ # Min and max depth for the plot --p-min-depth 5000 \\ --p-max-depth 130000 \\ # Evaluating diversity every 75 seqs depth --p-steps 75 \\ # Using average from 55 iterations for the diversity count --p-iterations 55 \\ --m-metadata-file metadata.file.txt \\ --p-metrics simpson_e \\ --p-metrics simpson \\ --p-metrics shannon \\ --p-metrics observed_otus \\ --p-metrics faith_pd \\ --o-visualization rarefaction-curve.qzv The command will take approx. 10 min; the result is a visualisation artifact. From the loaded file, you can select the metric to visualize as well as the grouping (there is one non-numerical column in the metadata file). The visualization will have two plots. The top plot is an alpha rarefaction plot and is primarily used to determine if the richness of the samples has been fully observed or sequenced. If the lines in the plot appear to level out (i.e., approach a slope of zero) at some sampling depth along the xaxis, that suggests that collecting additional sequences beyond that sampling depth would not likely result in the observation of additional features. If the lines in a plot dont level out, this may be because the richness of the samples hasnt been fully observed yet (because too few sequences were collected), or it could be an indicator that a lot of sequencing errors remain in the data (which is being mistaken for novel diversity). The bottom plot in this visualization is important when grouping samples by metadata. It illustrates the number of samples that remain in each group when the feature table is rarefied to each sampling depth. If a given sampling depth (depth D) is larger than the total frequency of sample S (i.e., the number of sequences that were obtained for sample S), it is not possible to compute the diversity metric for sample S at sampling depth D. If many of the samples in a group have lower total frequencies than D, the average diversity presented for that group at D in the top plot will be unreliable because it will have been computed on relatively few samples. When grouping samples by metadata, it is therefore essential to look at the bottom plot to ensure that the data presented in the top plot is reliable. Choose a rarefaction threshold for the normalisation step, is ultimately identifying the best tradeoff between losing sequencing depth within few samples or loosing entire samples. The best choice usually depends on the experimental design, if you have sample replicates you may lose a few of these without losing statistical power for the analysis, if not it may be choosing a lower threshold (and therefore loosing sequencing for the best sequenced samples you have ) Questions: Are any samples not fully sequenced? Choose a sampling depth (rarefaction threshold) to use for the alpha- and beta-diversity analysis, you can discuss with a class-mate. "],["13-Sequencing_controls_evaluation.html", "Chapter 13 Sequencing controls evaluation: beta-diversity without normalisation", " Chapter 13 Sequencing controls evaluation: beta-diversity without normalisation The current protocols for metagenetic experiments strongly suggest to always include positive and negative controls for any stage of the lab processing of the samples (including the sequencing). It is therefore likely that in your design you will have negative controls (to explore the microbiome derived by the kits used, the so-called kit-ome) and positive controls (mock or known communities, to investigate biases from the lab protocols or the bioinformatics pipeline). To investigate if the controls (especially the negatives) show contaminations and or suspicious similarity with the samples under investigation, it is a good practice to investigate beta-diversities before proceeding with the rarefaction step. That is because the rarefaction will probably exclude most of the negative controls containing not as many reads as the samples in analysis. In the experimental design used for this practical there are no controls. However, it may be good to look at the diversity before rarefaction to compare with the same after rarefaction. The following commands are used to obtain the Principal Coordinate Analysis (PCoA) for the beta-diversity using the bray-curtis distance. qiime diversity beta \\ --i-table table-dada2.qza \\ --p-metric braycurtis \\ --o-distance-matrix dada2.braycurtis.notNorm.diversity.qza qiime diversity pcoa \\ --i-distance-matrix dada2.braycurtis.notNorm.diversity.qza \\ --o-pcoa dada2.braycurtis.notNorm.diversity.pcoa.qza qiime emperor plot \\ --i-pcoa dada2.braycurtis.notNorm.diversity.pcoa.qza \\ --m-metadata-file metadata.file.txt \\ --o-visualization dada2.braycurtis.notNorm.diversity.pcoa.qzv These steps will take approx. 2 min. The final dada2.braycurtis.notNorm.diversity.pcoa.qzv artifact contains the first 3 axes for the PCoA analysis. It is possible to colour the samples by each metadata category group, to highlight if a specific metadata may have an effect on the diversity. "],["14-Diversity_analysis.html", "Chapter 14 Diversity analysis", " Chapter 14 Diversity analysis Alpha diversity is a representation of the diversity within a sample. There are many possible metrics for estimating alpha diversity (QIIME2 allows 30 metrics to be estimated), including the Shannon metric, the number of observed species and Faiths phylogenetic distance (Shannon, 1948, Faith, 1992). Beta diversity is diversity among different communities. There are many possible metrics to represent the distance among samples (QIIME2 allows 34 to be estimated), including weighted and unweighted UniFrac metrics (Lozupone and Knight, 2005, Lozupoune et al., 2007) and the Bray-Curtis metric (Bray and Curtis, 1957). QIIME2 includes a wrapper script to co-investigate alpha- and beta-diversity at the same time. This script includes only a selected list of alpha- and beta-diversity metrics, but are usually enough to investigate the dataset. It is possible to use different metrics using the single scripts for alpha and beta-diversity (https://docs.qiime2.org/2019.1/plugins/available/diversity/). qiime diversity core-metrics-phylogenetic \\ --i-table table-dada2.qza \\ --i-phylogeny rooted-tree.qza \\ # Chosen final sampling depth --p-sampling-depth 30000 \\ --output-dir dada2-diversity-30000 \\ --m-metadata-file metadata.file.txt This command will produce (in approx. 1 min) all the results within the directory specified with the --output-dir. The artifact rarefied_table.qza is the abundance table normalised by rarefaction at the specified sampling size. The output directory contains the artefact for each used diversity metrics (for alpha- and beta-diversity). The beta-diversity ordination plots are also included in visualisation objects (emperor.qzv files). In case of ITS or any marker for which it is not possible to obtain phylogenetic tree, the alternative command to use for the diversity analysis is: qiime diversity core-metrics, which lacks the --i-phylogeny options. Questions: Looking at the beta-diversity plot, one metrics of your choice, is there any metadata category reflecting the distribution of the samples in the plot? If you choose a different metric, do you get a different plot/results? Does a different sampling-depth does give a different result? Considering the alpha-diversity results for each metric, we need to explore if there is a group (within the metadata category) showing a higher diversity than the other groups, with a statistical significance and not by chance given the high number of data we are dealing with. The QIIME2 pipeline offers two alternative choices: for categorical or numerical metadata. In the first case a Kruskall-Wallis test will be used to compare the alpha-diversity distribution among the groups within the specified metadata category; in the second case, a ranked Spearman test will be used instead. cd dada2-diversity-30000 # For the Kruskal-Wallis qiime diversity alpha-group-significance \\ --i-alpha-diversity shannon_vector.qza \\ --m-metadata-file ../metadata.file.txt \\ --o-visualization shannon-group-significance.kw.qzv # For the ranked Spearman qiime diversity alpha-correlation \\ --i-alpha-diversity shannon_vector.qza \\ --m-metadata-file ../metadata.file.txt \\ --o-visualization shannon-group-significance.rs.qzv Both scripts should finish within a few seconds, giving a visualisation artifact including plots and statistical results. Questions: Is there any category (for one or more metadata category) showing a higher/lower alpha-diversity compared with the other? Is the p-value for this comparison significant (all the pvalues are corrected for false-discovery rate)? If you choose a different metric do you get different results? (Please look at both the Kruskal-Wallis and Ranked Spearman results!) Having identified a metadata category (co-variate) that potentially explain the distribution in the beta-diversity ordination plot obtained using a specific metric, it is now important to investigate, again, if that separation has a statistical significance or if it may have just be originated by chance. We will use the permanova test (you can choose anosim as alternative) to compare the grouping for a specific metadata category with the obtained distance metrics (at 999 permutations). qiime diversity beta-group-significance \\ --i-distance-matrix weighted_unifrac_distance_matrix.qza \\ --m-metadata-file ../metadata.file.txt \\ # Select one specific metadata column --m-metadata-column Location \\ # prmanova default, anosim as alternative choice --p-method permanova \\ --p-pairwise \\ --p-permutations 999 \\ --o-visualization weighted-unifrac-significance.location.qzv The script should finish within a few seconds, giving a visualisation artifact including plots and statistical results. Questions: Does the chosen grouping information result in statistical differences between two or more groups (as before the p-values are corrected for false-discovery rate)? Does using anosim instead of permanova change the result? And using a different ordination metric? What about choosing a different grouping (metadata category)? "],["15-Differential_abundance.html", "Chapter 15 Differential abundance analysis", " Chapter 15 Differential abundance analysis The ANCOM method to identify the differentially abundant taxa, is a complex method requiring different steps, for the description of the script used please refer to the script page (https://docs.qiime2.org/2019.1/plugins/available/composition/ancom/) and the ANCOM paper (https://www.ncbi.nlm.nih.gov/pubmed/26028277) . The steps to carry this out are: Collapse ASVs into taxa-bar-plots Add pseudo-count to the abundance table to convert 0 to 1 Run ANCOM selecting a categorical metadata to test If you are still in dada2-diversity-30000 folder, please remember to move out: cd .. First, we need to collapse the ASVs into taxa. This is done as seeing which ASVs are differentially abundant with no taxonomic information is not very useful. Let us choose greengenes level 5 which equates to family. qiime taxa collapse \\ --i-table table-dada2.qza \\ --i-taxonomy taxonomy.sklearn.qza \\ --p-level 5 \\ --o-collapsed-table comp-ancom-table-l5.qza Add pseudo-count to the abundance table to convert 0 to 1. This is required as ANCOM will fail with abundance values of 0. qiime composition add-pseudocount \\ --i-table comp-ancom-table-l5.qza \\ --p-pseudocount 1 \\ --o-composition-table comp-ancom-table-l5-pse.qza Finally, we run ANCOM. In this instance we will use Location as the metadata so we can find biomarkers that differentiate between StudentCorridor, StudentHome, Corridor and Toilet. qiime composition ancom \\ --i-table comp-ancom-table-l5-pse.qza \\ --m-metadata-file metadata.file.txt \\ --m-metadata-column Location \\ --o-visualization l5-ancom-Location.qzv Questions: Which families are discovered as biomarkers? Investigating these families, does this make sense? Do you get any genera as biomarkers that do not belong to families discovered as biomarkers? Does changing the metadata category let you infer something different? "],["16-Final_consideration.html", "Chapter 16 Final consideration", " Chapter 16 Final consideration Are the results you obtained with this pipeline making any sense? In a real scenario, you (as the owner of the dataset) are the one with the deepest knowledge of the dataset you are analysing, so it is upon you to answer this question. This answer needs to be inferred by gathering all the information you can on the samples, from literature or biochemical. If the answer is no, the following are points you can consider. Are there any missing taxa you know should be there? These taxa may be present but not being detected for a few reasons, first of all, are these represented in the taxonomical database you are using? If no, you should try with a different one (Greengenes or Silva). If they are, you can try with different taxonomical assignment methods. If this still does not work, you can change the method to pick up the representative sequence and/or the clustering at the earlier stages of the analysis. The failure could also be right at the beginning of the project design. It is worth checking if the PCR primers you are using can amplify these species. Are the primers known to impose bias on the community you are amplifying? Are the primers unable to amplify some taxon whose 16S rRNA sequences are too distant from the rest of the community? The literature may be able to help you on this topic. If you are happy with the composition, you can then explore the ecological differences among your samples. For this there are few other analyses you may want to approach: Functional analysis (PiCrust). We will cover this later! Inferring ecological interaction networks (SPIEC-EASI) More statistical analyses with STAMP Or you can import your results in R to post analyse them with Phyloseq CONGRATULATIONS YOU HAVE FINISHED THE ANALYSIS! If you have still time available you can try to repeat the analysis using different setting to compare the results (remember to use a different name for the output compared to what you used before), as an alternative you can read the suggested reading. "],["17-Resources.html", "Chapter 17 Resources 17.1 Suggested readings 17.2 Other useful resources 17.3 References", " Chapter 17 Resources 17.1 Suggested readings The QIIME2 tutorials page contains many useful protocols and possible usage for these scripts (https://docs.qiime2.org/2019.1/tutorials/). The QIIME scripts collection (http://qiime.org/scripts/index.html) includes many other useful scripts that we have not described, each script with its own description and tips for using it. We encourage you to explore this resource. A large resource containing links to literature on how easy it is to introduce bias into microbiome studies: http://www.opiniomics.org/the-unbearable-madness-of-microbiome/ Diversity of 16S rRNA Genes within Individual Prokaryotic Genomes Anna Y. Pei, William E. Oberdorf, Carlos W. Nossa, Ankush Agarwal, Pooja Chokshi, Erika A. Gerz, Zhida Jin, Peng Lee, Liying Yang, Michael Poles, Stuart M. Brown, Steven Sotero, Todd DeSantis, Eoin Brodie, Karen Nelson, and Zhiheng Pei (2010) APPLIED AND ENVIRONMENTAL MICROBIOLOGY. http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2893482/ Analysis, Optimization and Verification of Illumina- Generated 16S rRNA Gene Amplicon Surveys Michael C. Nelson, Hilary G. Morrison, Jacquelynn Benjamino, Sharon L. Grim, Joerg Graf. (2014) PlosONE http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0094249 Interpreting 16S metagenomic data without clustering to achieve sub-OTU resolution Mikhail Tikhonov, Robert W Leach and Ned S Wingreen (2015) ISME http://www.nature.com/ismej/journal/v9/n1/full/ismej2014117a.html De novo clustering methods outperform reference-based methods for assigning 16S rRNA gene sequences to operational taxonomic units Sarah L. Westcott and Patrick D. Schloss (2015) PeerJ http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4675110/ https://www.uab.edu/medicine/camac/images/10-A-Kumar_slide_show.pdf Waste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible. Paul J. McMurdie, Susan Holmes (2014) Plos ONE. http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003531 http://compbio.ucsd.edu/wp-content/uploads/2016/10/20170712_microbiome_16s_tutorial_noninteractive.pdf Normalization and microbial differential abundance strategies depend upon data characteristics. Sophie Weiss, Zhenjiang Zech Xu, Shyamal Peddada, Amnon Amir, Kyle Bittinger, Antonio Gonzalez, Catherine Lozupone, Jesse R. Zaneveld, Yoshiki Vázquez-Baeza, Amanda Birmingham, Embriette R. Hyde and Rob Knight (2017) Microbiome https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-017-0237-y Application of multivariate statiastical techniques in microbial ecology. Paliy O, Shankar V (2016) Molecular Ecology http://onlinelibrary.wiley.com/doi/10.1111/mec.13536/abstract Exact sequence variants should replace operational taxonomic units in marker-gene data analysis. Benjamin J Callahan, Paul J McMurdie &amp; Susan P Holmes (2017). https://www.nature.com/articles/ismej2017119 Optimizing taxonomic classification of marker gene amplicon sequences Nicholas A Bokulich, Benjamin D Kaehler, Jai Ram Rideout, Matthew Dillon, Evan Bolyen, Rob Knight, Gavin A. Huttley, J. Gregory Caporaso https://peerj.com/preprints/3208/ Denoising the Denoisers: An independent evaluation of microbiome 3 sequence error-correction methods. Nearing Jacob, Douglas Gavin, Comeau Andre, Langille Morngan https://peerj.com/preprints/26566.pdf Compositional data analysis of the microbiome: fundamentals, tools, and challenges. Tsilimigras, M.C. and Fodor, A.A. https://www.sciencedirect.com/science/article/pii/S1047279716300722 17.2 Other useful resources A list of very useful site to look at for questions, suggestion and protocols QIIME2 forum: https://forum.qiime2.org SEQanswers: http://seqanswers.com ResearchGate: https://www.researchgate.net/topics 17.3 References Aitchison J., (1982). The statistical analysis of compositional data. Journal of the Royal Statistical Society. Series B (Methodological), pp.139-177. Caporaso, J. G. et al. Global patterns of 16S rRNA diversity at a depth of millions of sequences per sample. Proc Natl Acad Sci USA 108, 45164522 (2011) Gloor GB, Macklaim JM, Pawlowsky-Glahn V, and Egozcue, JJ. (2017). Microbiome datasets are compositional: and this is not optional. Frontiers in microbiology, 8, p.2224. Hugerth, L.W. and Andersson, A.F., 2017. Analysing microbial community composition through amplicon sequencing: from sampling to hypothesis testing. Frontiers in microbiology, 8, p.1561. Pollock J, Glendinning L, Wisedchanwet T, and Watson M. The madness of microbiome: Attempting to find consensus best practice for 16S microbiome studies. (2018) Appl Env Microbiology Rivers, A.R., Weber, K.C., Gardner, T.G., Liu, S. and Armstrong, S.D., 2018. ITSxpress: Software to rapidly trim internally transcribed spacer sequences with quality scores for marker gene analysis. F1000Research, 7. Shannon, C.E., 1948. A mathematical theory of communication. Bell system technical journal, 27(3), pp.379-423. Weiss S, Zech Xu ZZ, Peddada S, Amir A, Bittinger K, Gonzalez A, Lozupone C, Zaneveld JR, Vázquez-Baeza Y, Birmingham A, Hydev ER, and Knight R. Normalization and microbial differential abundance strategies depend upon data characteristics. (2017) Microbiome. 3;5(1):27 Werner JJ, Koren O, Hugenholtz P, DeSantis TZ, Walters WA, Caporaso JG, Angenent LT, Knight R, Ley RE. Impact of training sets on classification of high-throughput bacterial 16s rRNA gene surveys. (2012) ISME J. 6(1):94-103. Yarza, P., Yilmaz, P., Pruesse, E., Glöckner, F.O., Ludwig, W., Schleifer, K.H., Whitman, W.B., Euzéby, J., Amann, R. and Rosselló-Móra, R., 2014. Uniting the classification of cultured and uncultured bacteria and archaea using 16S rRNA gene sequences. Nature Reviews Microbiology, 12(9), p.635. Cutadapt Martin M. Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet.journal, 17(1):10-12, May 2011. QIIME2 (Quantative Insights Into Microbial Ecology) Bolyen E, Rideout JR, Dillon MR, Bokulich NA, Abnet C, Al-Ghalith GA, Alexander H, Alm EJ, Arumugam M, Asnicar F, Bai Y, Bisanz JE, Bittinger K, Brejnrod A, Brislawn CJ, Titus Brown C, Callahan BJ,Caraballo-Rodríguez AM, Chase J, Cope E, Da Silva R, Dorrestein PC, Douglas GM, Durall DM, Duvallet C, Edwardson CF, Ernst M, Estaki M, Fouquier J, Gauglitz JM, Gibson DL, Gonzalez A, Gorlick K, Guo J, Hillmann B, Holmes S, Holste H, Huttenhower C, Huttley G, Janssen S, Jarmusch AK, Jiang L, Kaehler B, Kang K, Keefe CR, Keim P, Kelley ST, Knights D, Koester I, Kosciolek T, Kreps J, Langille MGI, Lee J, Ley R, Liu Y, Loftfield E, Lozupone C, Maher M, Marotz C, Martin BD, McDonald D, McIver LJ, Melnik AV, Metcalf JL, Morgan SC, Morton J, Naimey AT, Navas-Molina JA, Nothias LF, Orchanian SB, Pearson T, Peoples SL, Petras D, Preuss ML, Pruesse E, Rasmussen LB, Rivers A, Robeson MS, Rosenthal P, Segata N, Shaffer M, Shiffer A, Sinha R, Song SJ, Spear JR, Swafford AD, Thompson LR, Torres PJ, Trinh P, Tripathi A, Turnbaugh PJ, Ul-Hasan S, van der Hooft JJJ, Vargas F, Vázquez-Baeza Y, Vogtmann E, von Hippel M, Walters W, Wan Y, Wang M, Warren J, Weber KC, Williamson CHD, Willis AD, Xu ZZ, Zaneveld JR, Zhang Y, Knight R, Caporaso JG (2018) QIIME 2: Reproducible, interactive, scalable, and extensible microbiome data science. PeerJ pre-prints https://peerj.com/preprints/27295/ BLAST Altschul S.F., Gish W., Miller W., Myers E.W. and Lipman D.J. (1990). Basic local alignment search tool. J. Mol. Biol. 215: 403-410. http://blast.ncbi.nlm.nih.gov/Blast.cgi Bray-Curtis Bray, J. R. and J. T. Curtis. (1957). An ordination of upland forest communities of southern Wisconsin. Ecological Monographs 27:325-349 Chao1 Chao, A. 1984. Non-parametric estimation of the number of classes in a population. Scandinavian Journal ofStatistics, 11:265-270. Colwell, R.K. and Coddington, J.A. 1994. Estimating terrestrial biodiversity through extrapolation. Philosophical Transactions of the Royal Society B: Biological Sciences, 345:101-118. DADA2 Callahan BJ, McMurdie PJ, Rosen MJ, Han AW, Johnson AJA. DADA2: High-resolution sample inference from Illumina amplicon data. Nat Methods. 2016. 13, 581-583. GNEISS Morton JT, Sanders J, Quinn RA, McDonald D, Gonzalez A, Vázquez-Baeza Y, Navas-Molina JA, Song SJ, Metcalf JL, Hyde ER, Lladser M, Dorrestein PC, Knight R. (2017). Balance Trees Reveal Microbial Niche Differentiation mSystem 17;2(1) Greengenes DeSantis, T. Z., P. Hugenholtz, N. Larsen, M. Rojas, E. L. Brodie, K. Keller, T. Huber, D. Dalevi, P. Hu, and G. L. Andersen. (2006). Greengenes, a Chimera-Checked 16S rRNA Gene Database and Workbench Compatible with ARB. Appl Environ Microbiol 72:5069-72. Faiths Phylogenetic Diversity (PD) Faith. 1992. Conservation evaluation and phylogenetic diversity. Biological Conservation 61: 1-10 Faith DP and Baker AM. Phylogenetic diversity (PD) and biodiversity conservation: some bioinformatics challenges (2006) Evol. Bioinform. 2: 121128. UniFrac Lozupone, C.; Knight, R. (2005). UniFrac: A New Phylogenetic Method for Comparing Microbial Communities. Applied and Environmental Microbiology 71 (12): 82288235 http://bmf.colorado.edu/unifrac/ UniFrac Lozupone, Hamady, Kelley &amp; Knight. (2007). Quantitative and qualitative (beta) diversity measures lead to different insights into factors that structure microbial communities. Appl Environ Microbiol 73 (5): 1576-85 ANCOM Mandal S, Van Treuren W, White RA., Eggesbø M., Knight R., and Peddada, S.D. (2015). Analysis of composition of microbiomes: a novel method for studying microbial composition. Microbial ecology in health and disease, 26(1), p.27663. "],["18-Appendix.html", "Chapter 18 Appendix 18.1 Alpha diversity metrics", " Chapter 18 Appendix 18.1 Alpha diversity metrics 18.1.1 Observed species The observed number of species is defined as the number of distinct OTUs within a sample. 18.1.2 PD (phylogenetic diversity) The PD metric represents the minimum total branch length that covers all taxa within the sample on a phylogenetic tree (Faith, 1992). A smaller PD value therefore indicates a reduced expected taxonomic diversity whilst a large PD value indicates a higher expected diversity. 18.1.3 Shannon Shannons index accounts for both abundance and evenness of the species present. The proportion of species i relative to the total number of species (pi) is calculated, and then multiplied by the natural logarithm of this proportion (lnpi). The resulting product is summed across species, and multiplied by -1. 18.1.4 Weighted and unweighted UniFrac distances The UniFrac metric is a phylogenetic distance measure between two samples and is defined as the sum of the unshared branch lengths between two samples divided by the total branch length (shared + unshared) of two samples (Lozupone and Knight, 2005). This results in calculating the fraction of the branch length unique to each sample (ie. the higher this value is, the more dissimilar two samples are). Unweighted UniFrac distances consider only OTU presence/absence whilst weighted UniFrac distances take into account OTU abundance and weigh branches accordingly (Lozupone and Knight, 2005; Lozupone et al., 2007). 18.1.5 Bray-Curtis The Bray-Curtis metric is a dissimilarity measure that can quantify the level of difference between two samples. Two identical samples would have a Bray-Curtis measure of 0. There are two definitions of the Bray-Curtis metric currently used in the literature. The Faith method (Faith, 1987) is defined by the following formula: CBC = 1  ( 2a / (b + c) ) Where: a = # OTUs present in both samples b = # OTUs present only in sample 1 c = # OTUs present only in sample 2 The second definition of the Bray-Curtis metric is often known as the Magurran method (Magurran, 1988) and is defined by the following formula: CN = 2jN / (Na + Nb) Where: Na = the total number of individuals in site A Nb = the total number of individuals in site B 2jN = the sum of the lower of the two abundances for species found in both sites "]]
