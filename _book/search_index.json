[["01-Bacterial_16S_metabarcoding.html", "Bacterial 16S metabarcoding Chapter 1 Introduction", " Bacterial 16S metabarcoding Luca Lenzi and Matthew Gemmell 2021-02-05 Chapter 1 Introduction This practical session aims to introduce you to the analysis of bacterial 16S metabarcoding with QIIME2. The topics covered are: Logging in to our teaching environment "],["02-Background.html", "Chapter 2 Background 2.1 16S rRNA 2.2 ITS and other possible marker genes 2.3 Amplicon sequencing", " Chapter 2 Background One of the most common aims of metagenomic analyses is to quantify the composition and diversity of a community (usually a community of prokaryotes). This can be done in several ways. A common approach is high-throughput amplicon sequencing, usually of a region of the bacterial 16S SSU rRNA gene; another is shotgun metagenomic sequencing, where the whole genomic content of a sample is sequenced. In the first approach, amplicons act as ‘tags’ identifying the different bacterial species present in the sample, which can be both identified and quantified to describe the composition of the bacterial community (called also metagenetics or metaprofiling). In the second approach, whole genomes, rather than just representative amplicons, are sequenced (therefore called shotgun metagenomics). This DNA can be assembled, or the source of the reads can be identified and quantified in a broadly similar way to 16S analysis. In this practical exercise, we will analyse amplicon sequencing data, obtained by amplification of the variable region 4 of the 16S gene, using primer 515FB-806RB described in http://press.igsb.anl.gov/earthmicrobiome/protocols-and-standards/16s/ (Caporaso et al, 2011). The sequences were obtained from the Illumina MiSeq platform, 2x250bp reads, and the analysis process will be based on the software package QIIME2 (“Quantitative Insights Into Microbial Ecology,” https://qiime2.org). We will explore the bacterial populations sampled at various locations in the Bioscience building: toilets and corridors from different floors. 2.1 16S rRNA 16S ribosomal RNA is a structural RNA which is a component of the prokaryotic ribosome. Due to this fact, the ribosomes are the site of protein synthesis, all prokaryotes have at least a 16S rRNA gene that codes for the 16S ribosomal RNA. The 16S rRNA gene is utilised in reconstructing phylogenies due to its slow rate of evolution, its size and its functional constancy. If the function of 16S rRNA changed then the cell could not synthesise protein correctly and so will not survive. The 16S rRNA gene is ~1,500bp long and is made up of 9 variable regions separated by conserved regions. The variable regions evolve at a faster rate allowing differentiation between bacterial taxa. The conserved regions evolve at a slower rate which allows areas to carry out universal amplification on the gene. The nine variable regions are generally called V1, V2, V3 etc. Secondary structure of 16S rRNA of Esherichia coli (Yarza et al, 2014) 2.2 ITS and other possible marker genes It is very common to perform analysis with marker genes other than 16S, e.g. to study communities of fungi, insects or any other eukaryote species. From the perspective of the bioinformatics analysis, the same overall pipeline can be used for most of the marker genes. ITS (Internal Transcribed Spacer) is a commonly used marker alternative to 16S. QIIME2 can be used to analyse ITS with a few steps and commands required which are unnecessary for 16S rRNA data. In this tutorial, locations will be highlighted where you should consider a pipeline variation if you are using ITS. In general, we recommend searching the literature so you can be aware of the state-of-the-art methods for the analysis of your marker of interest. 2.3 Amplicon sequencing The use of high-throughput amplicon-sequencing has proven to be powerful and accurate for microbial (or fungal or with any other marker gene) community analysis. It is currently the preferred choice used to investigate biological communities (bacterial or eukaryotic) in many samples and conditions. Some of the reasons for this method’s popularity are: It is relatively easy to perform. It can be performed with many samples. It is relatively fast and cheap. On the negative side, there are many steps which may potentially introduce biases in the final result: Experimental design, sampling, storage and DNA extraction methods are known to potentially reduce the initial bacterial population processed and sequenced. Any reagent used may add exogenous bacterial population to the samples (potentially contaminating or changing the initial bacterial amount). Several papers discuss how the PCR protocol used for the amplification of the DNA material may affect the final results (such as the creation of chimeric sequences or by preferentially amplifying some bacterial). The choice of sequencing platform may result in the identification of different species in the same samples by having its own characteristic error-profile. From the bioinformatics perspective, the length of the sequences, and the pipeline used for the analysis are also able to add variability to the final results. the identification of the species in the samples in analysis can be affected by the quality and completeness of the database used for the analysis and may become less precise at lower taxonomy levels such as ‘genus’ and ‘species’ (Hugerth and Andersson, 2017). All these aspects need to be taken into account in the discussion of the results. Above shows a representation of amplicon sequencing. a) Different species are shown as different colours, with the indication of which species are in the site under investigation. Some species may be excluded from the sequencing because they are missed by the sampling methods (purple), lost during the sample preparation (not kept by the conservation methods), lost by the extraction technique, or not amplified in the PCR step (pink). b) Representation of the number of sequences obtained for a sample, showing that increasing the number of sequences increases the probability to retrieve low-abundant species in the samples. The main purpose for this analysis is to infer the number and type of species in the initial sampling site by the abundance of the sequences obtained by the sequencing experiment. In order to do this effectively, the use of mock communities and negative controls is strongly suggested to evaluate the effect of any possibly introduced bias. Additionally, normalisation of the data is absolutely necessary to compare the diversity between sample groups. "],["03-Intro_to_qiime2.html", "Chapter 3 Introduction to QIIME2 3.1 Artifacts 3.2 Workflow 3.3 Prepare the sequence dataset 3.4 Amplicon Sequence Variants identification 3.5 Assign a taxonomic classification to each ASV 3.6 Build phylogenetic tree 3.7 Data normalisation 3.8 Alpha-diversity 3.9 Beta-diversity 3.10 Differentially Abundant Analysis", " Chapter 3 Introduction to QIIME2 Since January 2018, the QIIME project released the QIIME2 (qiime2.org, Bolyen et al., 2018) pipeline to analyse amplicon sequencing data. The QIIME1 scripts, in its latest release QIIME1.9.1, are still available (and their methods are still valid) however the suggestion is to use QIIME2, as QIIME1 is no longer supported. In the following practical we will use the QIIME2 released on January 2019 (given the active development on the tool this may not be the most recent release at the time of this workshop). To install QIIME2, please refer to its instruction page: https://docs.qiime2.org/2020.11/install/ 3.1 Artifacts The QIIME2 pipeline produces and uses ‘artifact’ files, these contain data and metadata and may be of two types: result or visualization. Result files (.qza): This file type contains the results of a method, which accepts other ‘artifacts’ and specific settings as input, in order to apply a procedure creating a new artifact (e.g. loading sequences, error correction, alpha- or beta-diversity). Visualisation files (.qzv): This file type contains the results of a specific procedure to obtain an object that can only be used to visualize the results. These files can be loaded into the following web-site https://view.qiime2.org, where the interactive visualisations can be viewed. Please note that only chrome and Firefox are supported by this QIIME2 website. The final resulting table may be exported by the ‘download’ option once the data are loaded into the above website as well as by a specific exporting procedure. 3.2 Workflow The steps for the analysis are listed below, mainly taken from https://docs.qiime2.org/2019.1/tutorials/. The square brackets show the tool used for the specific step in this practical (all performed within the QIIME2 pipeline). Representation of the step proposed for the analysis (http://compbio.ucsd.edu/wp-content/uploads/2016/10/20170712_microbiome_16s_tutorial_non-interactive.pdf) Prepare the sequence dataset Remove PCR primers [Cutadapt – QIIME2] Amplicon Sequence Variants identification [DADA2 – QIIME2] Assign a taxonomic classification to each AVS [sk-learn – QIIME2] Train naïve-classifier for assignment [QIIME2] Taxonomy assignment of the identified ASVs [QIIME2] Make a phylogeny tree for the ASVs [QIIME2] Alignment of the identified ASV [QIIME2] Masking low quality alignment [QIIME2] Creating the un-rooted phylogenetic tree [QIIME2] Creating the rooted phylogenetic tree [QIIME2] Summarise the taxonomy data for each sample and plot results [QIIME2] Estimate and plot alpha diversity [QIIME2] Estimate and plot beta diversity (if &gt;1 sample) [QIIME2] Differential abundance analysis (if &gt;1 sample) [QIIME2] 3.3 Prepare the sequence dataset The read set you will be using in this tutorial will be a raw dataset. It still includes low quality sequences, Illumina sequencing adapters as well as PCR primers. Before proceeding with the analysis, it is a good strategy to investigate the quality of the sequences. The PCR primers used for the amplification may have degenerate positions (required for annealing to the large variety of species in the samples). This adds ‘random’ variability outside the target region. These unknown sequences may affect the subsequent taxonomy identification as well as the error-correction step. We will use Cutadapt to remove the PCR primers before any other step. If the analysis is based on a marker gene different than 16S, other quality trimming may be required. In the case of the ITS marker gene, the common practice is to trim off the conserved regions (SSU, 5.8S or LSU) that may be contained in the final amplicon. The ‘ITSxpress’ software (Rivers et al., 2018) is designed for this specific task and it is available as a QIIME2 plug-in, though it requires specific installation steps because it is not installed with the basic (core) installation process. It could be found among the list of third-party QIIME2 available plug-ins (https://library.qiime2.org/plugins/ ). 3.4 Amplicon Sequence Variants identification The key element of this type of metagenomic analysis is the identification of the different rRNA variants in the sample. 3.4.1 OTUs The most used procedure to identify OTUs (Operational Taxonomic Units) is through the clustering of reads into groups that are sufficiently similar to one another. These grouped reads are likely to come from the same rRNA gene, genome or taxa group. The identified OTUs are a feature of the sequence dataset, heavily dependent on the similarity level used for OTU identification (the most commonly used threshold is 3% dissimilarity/97% similarity to group reads into species OTUS). Therefore, de novo OTUs identified in two different data sets cannot be compared. There is no single perfect tool for this step; but a few of the most widely used are: UCLUST (the default used by QIIME1.9.1) VSEARCH CD-Hit SWARM (if you work with QIIME1.9.1 we recommend using SWARM for this step) The number of reads in each OTU should reflect the number of copies of the gene in the sample, thus providing a quantitative measure of diversity. 3.4.2 ASVs There are now many bioinformatics methods to resolve amplicon sequence variants (AVS) from Illumina data. These methods do not impose the arbitrary dissimilarity thresholds that define molecular OTUs. The two methods available in QIIME2 are DADA2 and deblur. ASV methods infer the biological sequences in the sample prior to the introduction of amplification and sequencing errors, and distinguish sequence variants differing by as little as one nucleotide. The methods use a de novo process in which biological sequences are discriminated from errors on the basis of, in part, the expectation that biological sequences are more likely to be repeatedly observed than error-containing sequences. Unlike de novo OTUs, ASVs are consistent labels because ASVs represent a biological reality that exists outside of the data being analysed: the DNA sequence of the assayed organism. Thus, ASVs inferred independently from different studies or different samples can be validly compared. The following picture (http://ju.outofmemory.cn/entry/332219) shows how DADA2 (an ASV method) and OTU processes compare each other. This shows how the canonical creation of OTUs creation by clustering may lead to an overestimation of the size of the OTUs due to the presence of errors, from either PCR or sequencing. Much of the work involved in analysis of amplicon-based metagenomic data is that of separating true variants from errors introduced by sequencing. These errors include miscalling of nucleotides and the generation of chimeric sequences. For sequencing purposes, an aliquot of PhiX phage DNA is added to each sample before sequencing, both DADA2 and deblur include a step aimed to exclude any PhiX associated reads. To remove PCR chimeric artefacts, a further filter step is applied by both. QIIME 2 Authors suggest using DADA2 for read pairs and ‘deblur’ for already paired (stitched/joined) sequences. Please note that it is good practice to remove/trim out sequences containing Ns before the error correction step. It is not suggested to denoise with DADA2 samples from different sequencing lanes, because each lane may introduce different sequencing bias. It is possible to collate the denoised abundance tables and representative sequences afterward, recording the sequencing lane for each sample in a specific metadata column. The ‘deblur’ denoise tool may be used in this case because it should be less sensitive to these possible biases, however it is good practice to keep the lane of origin in the metadata (with the second benefit that ‘deblur’ is also faster than ‘DADA2’). 3.5 Assign a taxonomic classification to each ASV The sequence of each ASV is compared with the selected database, to identify the most likely taxonomy for each ASV. Unfortunately different parts of the taxonomic identification step may lead to different results for the same ASV. Different databases may result in different taxonomic classification for the same ASV. The choice of tool used for taxonomic assignment may also impact the results in a similar way. The current version of QIIME2 allows you to select from either the Scikit-learn classifier (a classifier which applies a machine learning approach and therefore needs training before use) or BLAST+ and VSEARCH (for a global alignment approach followed by a last common ancestor search) for this step. In the practical we will use Scikit-learn (similar to the RDP tool widely used so far). It has been shown that (at least in the case of 16S analysis) taxonomic classification accuracy improves when the classifier is trained with sequences derived from the amplicon region only (Werner et al., 2012). 3.6 Build phylogenetic tree To include phylogenetic diversity metrics in the diversity analysis, such as UniFrac distance metric, the construction of a phylogenetic tree for the identified AVS previously identified is required. QIIME2 supports MAFFT for the alignment and MASK to mask the alignment sections that are not phylogenetically informative. Unrooted and rooted trees may be created. For some marker genes it is not possible to build phylogenetic tree (ITS is among these), and it is therefore important to know the properties of the marker in use. Consequently, it is not possible to use any diversity metrics that requires the phylogenetic distance as input. 3.7 Data normalisation Any further analyses to compare the identified ASVs among sample groups (either alpha- or beta-diversity or differential abundance) should account for the features of the abundance table that can cause erroneous results (Weiss et al., 2017). These features are: The microbial community in each sample may be represented by different numbers of sequences (i.e. sequencing depth for each sample). The abundance table is usually sparse. That is, most of the ASVs are present only in a few samples and therefore the abundance table contains many ‘0’ values (it is also possible that a particular species is present in a sample but below the detection limit of the methods). The total number of sequences obtained reflect the relative abundance of species sequenced rather that the absolute abundance of the species present in the sample (this is commonly referred as ‘compositional nature’ of the data). The relative abundances for the taxa are therefore not independent as in the underlying assumption of many frequently used statistical methods (Gloor et al., 2017). A normalisation step for the data is required to mitigate these effects and to allow an easier data interpretation. The most used normalisation methods are: Normalisation by rarefaction. This is performed by reducing all the samples at the same sequence count, by random sub-sampling of the sequences. This method may lead to a potential reduction of the species in your dataset (alpha-diversity) and to the exclusion of any samples not reaching the selected total count per sample. DESeq method (borrowed from transcriptomic research) Scaling the abundance table by a fixed value or proportion. Applying a log-ratio transformation proposed by Aitchinson (1982) in analogy of compositional dataset. This is aimed to convert the abundance data into scales on which it is possible to apply conventional statistical procedures. Methods b-d convert the abundance table in a normalised-abundance table with different strength and pitfalls, therefore they can affect results for beta-diversity and differentially abundant analysis. These normalisation methods were compared by Weiss and colleagues (2017), but their simulations show that different methods may result in different sensitivity and different false discovery rates. In this tutorial, following the QIIME2 current tutorial, we will apply the following normalisation methods: The ‘rarefaction’ method, in the context of the alpha- and beta-diversity analysis. The ‘centered log-ratio transformation’ (clr-transformation) method, in the context of the differential abundance analysis. 3.8 Alpha-diversity Alpha-diversity is used to measure the diversity within a sample. It is calculated as a value for each sample. Different metrics were developed to calculate diversity in different ways. It combines richness (a measure of the number of species in the sample) and evenness (a measure of the relative abundance of different species that make up the richness of that sample). Alpha diversity measures cannot be compared unless they have been normalised for the difference in sequencing depth between samples. The QIIME2 release we will use supports the following alpha-diversity measures, amongst others: Chao1, Shannon, Simpson, Simpson evenness, Faith’s Phylogenetic Diversity (the only one considering the phylogenetic relationships among the ASVs). The alpha-diversity metric used for the analysis must be chosen carefully, considering its mathematical definition in relation of the behaviour of the tools used for the previous steps. An important point to consider is whether the chosen metric uses ASVs with only 1 sequence (‘singletons’) to perform some estimation on the dataset or not. The Chao1, as one example for this, uses the number of singletons in the dataset to infer the total number of singletons in the population. However, the DADA2 denoising step excludes ‘singletons’ from the final output, making Chao1 measures not applicable to its resulting abundance tables. A second consideration regards if the phylogenetic tree is available enabling the use of the Faith’s Phylogenetic Diversity metric, for markers such as ITS this metric would not be possible. 3.9 Beta-diversity Beta-diversity is a term for the comparison of samples to each other. It is also referred as beta-diversity ordination, because it uses one (or more) technique/s to arrange samples along axes on the basis of their composition to highlight the differences. The current QIIME2 release supports only the Principal Coordinates Analysis (PCoA) method to investigate beta-diversity (within the old QIIME1 pipeline you could perform nMDS as well). The starting point of the analysis is a dissimilarity matrix, which is used to perform a Principal Component Analysis (PCA) to reduce the dimension for display purpose. The axes obtained from the PCA analysis are then compared with the categories in the metadata file to identify patterns. A few of the commonly used beta diversity metrics supported by QIIME2 are: Jaccard: A non-phylogeny based method that takes into account only presence/absence of a ASVs to measure the distance between two samples. Bray-Curtis: A non-phylogeny based method that takes into account the number of ASVs as well as their abundance while measuring the distance between two samples. Un-weighted UniFrac: Uses the presence and absence of ASVs and phylogenies. Weighted UniFrac: Uses the abundance information of ASVs and phylogenies. As discussed for the alpha-diversity, before proceeding with the beta-diversity analysis the raw abundance table for the identified ASVs needs to be normalised, to this QIIME2 suggests using the rarefaction methods, in particular at the same rarefaction threshold used for the alpha diversity. The choice of the beta-diversity distance metric to use will strongly affect the results, it therefore common practice to compare the results obtained with different metrics. Again, not all the metrics may be applicable to all the marker genes, for example the UniFrac distances could not be easily used in the case of ITS, because ITS sequences are quite difficult to align onto phylogenetic trees. 3.10 Differentially Abundant Analysis The identification of taxa that are differentially abundant across experimental conditions may be an important result for many types of metagenetics analyses. This step is extremely dependent on the normalization methods used to compare the samples: using different normalisation methods may lead to different results (consequently this is another active area of research). QIIME2 supports two normalisation methods to investigate differentially abundant taxa across experimental conditions: ANCOM (Mandal et al., 2015) and GNEISS (Morton et al, 2017). Both methods are based on the conversion of the abundance values using the clr-transformation method prior to any comparison. Because the conversion is based on a logarithmic transformation, all the value in the abundance table will be increased by ‘1’ to avoid ‘0’ counts (pseudo-counts). These methods may therefore artificially increase the alpha-diversity for the samples as well as decrease the beta-diversity distances in the dataset. In this analysis we will use the ANCOM method following the current QIIME2 tutorial. This method computes the log-ratio for every possible pair of the identified taxa (using the mean group values for the clr-transformed abundance) and reports how many times the hypothesis “H 0 = X is not differentially abundant” is rejected for each taxa ‘X.’ That is the ‘W’ statistics, the higher this value is the more significant the ASV/taxa X is differentially abundant between the tested groups. This test assumes that a large number of ASVs did not change in abundances between groups. If, in the results, more than 25% of the ASVs changes in the examined contrasts, the underlying hypothesis for the ANCOM test may be not fulfilled, and there is the chance that the results may be misleading. Examples of questions to answer - Are there differences in taxa at various levels of taxonomy? - What are the most abundant ASVs (or species)? - What are the rare ASVs present (either real or still retained sequencing error)? - Where are the rare ASVs present (if not sequencing error)? - ASVs correlation: is there a correlation between ASVs and other attributes of samples, like pH or other environmental conditions? "],["04-Cluster_Introduction.html", "Chapter 4 Cluster Introduction 4.1 Logon instructions 4.2 The Terminal Window", " Chapter 4 Cluster Introduction 4.1 Logon instructions For this workshop we will be using Virtual Network Computing (VNC). You will log onto our machines so you can access our VNC desktops. Prior to loging in you will need to know the following key: The VNC will be set to full screen by default. F8 will bring up a menu in the VNC that will allow you to disable full screen. Follow the below instructions to log in to our Linux teaching VNC: Windows Go to the following link: http://ada01.liv.ac.uk/pcvnc.exe Save the file as “pcvnc.exe” Run the file Enter your password when the prompt appears Mac Open a terminal Run the following command in the terminal curl -s http://ada01.liv.ac.uk/MacVNC.sh | KEY=&lt;password&gt; bash &lt;password&gt; is replaced with your password Linux Open a terminal Run the following command in the terminal curl -s http://ada01.liv.ac.uk/LinuxVNC.sh | KEY=&lt;password&gt; bash &lt;password&gt; is replaced with your password You will now be in a logged-in Linux VNC desktop with two terminals. You will see something like below (there may be only one terminal which is fine). If you do not see something similar please ask for assistance. If the VNC is taking up to much space of your screen you can move it so alot of it is off the screen. Ensure you can see one whole terminal. These instructions will not work outside of this workshop. If your workplace has its own Linux cluster please ask your cluster manager for a user guide. If you would like to install your own Linux OS on your desktop or laptop we would recommend Ubuntu. The following link is a guide to install Ubuntu: https://www.ubuntu.com/download/desktop/install-ubuntu-desktop. If you use a USB you need to create a bootable USB stick. The following link will assist: https://www.ubuntu.com/download/desktop/create-a-usb-stick-on-windows 4.2 The Terminal Window In our case the terminal window looks like the picture below. We are using the terminal window as our shell to interpret our commands to the kernel. Depending on your system and preferences it may look different. Already there is useful information for us on the terminal window. nsc006: This is the login name, also known as the username. In this case nsc006 is a demonstrator’s account. Your screen should show a different account name which will be your username for the Linux machine/cluster you are logged into. gauss03: This is the machine name the user is logged into. ~: This represents the current directory of the user, or the directory a command was run in. In the Linux OS and others ‘~’ is a shortcut to the user’s home directory. Everything after the ‘$’ is where commands are typed into the terminal. This is also referred to as the command line. To open a new terminal window, right click on the main screen, choose Applications -&gt; Shell -&gt; bash "],["05-Linux_quick_user_guide.html", "Chapter 5 Linux quick user guide 5.1 Accessing the data and navigating the command line.", " Chapter 5 Linux quick user guide In the following parts of the practical exercise, descriptions of commands will be marked by hash character, #, these lines should not be typed in the terminal. e.g. # description; Commands directed to the bash terminal will be in red. e.g. cat filename Run the commands one after the other, from the command line. When a command’s length exceeds the width of the line available in the paragraph, the convention used in this document is to represent the ‘incompleteness of the command in the first line’ by ending it with a \\ sign. You may choose to split the command onto more than one line using this method in the shell or you may type the second line of the command straight after the first. In the former case, after typing the \\ and pressing ENTER, the prompt will show a &gt; sign indicating it is waiting for more command. This prompt &gt; is NOT reported in the command you have to type, so in any case this document showing a command line starting with the &gt; sign please be careful to type it. 5.1 Accessing the data and navigating the command line. In Unix, everything works via commands on the command line. Also, the Unix environment consists of directories which may contain other directories and/or files. At any one time you are in a directory, which is within another directory and so on, and there are directories ‘below’ you, which you can move into. When you type pwd, you see the full path to your location, or “working directory” (e.g. /pub39/tea/luca/Metagenetics_2019). The directories are separated by “/.” The initial “/” is the root directory (the directory that contains everything else). When you first log in, you are in your home, the directory containing all the files and directories that you create. To make a directory, move into it, see where you are, what else is there and move up out of it, try these commands. mkdir adirectory cd adirectory pwd ls cd .. ls rm –r adirectory Here, cd changes your directory (.. means “jump up a level”) and ls lists the files and directories you can see (the -l option gives more information about each file/dir). You can delete a file or directory using the rm command, adding the -r option for a directory. Use these until you are comfortable navigating around. Now you need to obtain the raw data you will be analysing in this workshop. Create a main directory for the workshop and copy the directory of workshop data from its location (/pub39/tea/luca/Metagenetics_2019/RawReads) to your directory (.) using the cp command. The -r option allows you to copy an entire directory. cd ~ mkdir Metagenetics cp -r ~luca/Metagenetics_2019/RawReads ./Metagenetics/RawReads cp ~luca/Metagenetics_2019/PairedEndFastqManifestPhred33.csv \\ ./Metagenetics cp ~luca/Metagenetics_2019/metadata.file.txt \\ ./Metagenetics Take a look at the data files ls -l Metagenetics/RawReads Now navigate into the directory, where you will do the analyses cd Metagenetics Now you will explore the data you are going to analyse. It is important to get a feel for the data and how it should and shouldn’t look. If the data were generated by Illumina (HiSeq or MiSeq), they will be in fastq format, a text format that can be easily viewed. If the data are Illumina (HiSeq or MiSeq) and were generated by the CGR, these are the raw files which are already demutliplexed using the software CASAVA but were NOT postprocessed to remove adapter sequences and low-quality bases (as per standard protocol prior to most analysis). If your data is paired-end (MiSeq data will be), then each sample has two data files. E.g.: 1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz 1K1E_AAGAGGCA-GTAAGGAG_L001_R2_001.fastq.gz In this case, the names denote sample 1, barcode AAGAGGCA-GTAAGGAG, lane 1 (L001), forward reads (R1) or reverse reads (R2), file 1 (001). Files are in fastq format and are often compressed with gzip (.gz). Files are typically very large. Hence you must be careful to handle them in the right way. They are usually too large to simply open in a text editor, so don’t try. Instead, you should use Unix commands and scripts to manipulate them. Ensure the Illumina reads are in fastq format by having a look. To view the top of the file, use the head command (tail is an equivalent command which lets you view the end of a file, while less and more allow you to scroll through the file). In here we will use the zless command which is able to open files compressed with gzip. zless RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz Notice that each read is represented by 4 lines: The first line is the read identifier. The second line is the sequence, and the fourth line is the quality score for this sequence. Qualities are in ASCII codes (in which a symbol represents a number: in this case the quality of the basecall). Note that the barcode sequence is displayed in the read header (but it may contain Ns). At this stage, you can get some information about your data. For instance, how many reads do you have? We can use the grep command to find every match to the pattern ^+$ (^=start of line, $=end of line, so match a line with a single + on it). There is only one line like this per read so the number of matches = the number of reads. The -c option makes grep return the count of the number of matches (rather than the matches themselves). zgrep -c “^+$” 1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz You should obtain: ~/Metagenomics/RawReads$ zgrep -c “^+$”1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz #result = 53731 "],["06-QIIME2_analysis_workflow.html", "Chapter 6 QIIME2 analysis workflow 6.1 Workflow", " Chapter 6 QIIME2 analysis workflow 6.1 Workflow The ‘QIIME2’ analysis workflow comprises of nine steps: Import sequences into QIIME2 artifact Trim the PCR primer sequences De-novo amplicon sequence variants identifications Assign a taxonomic classification to each ASV Make a phylogenetic tree of the identified ASVs Sequencing depth evaluation: rarefaction plot Sequencing controls evaluation: beta-diversity without normalisation Diversity analysis: alpha and beta Differential abundance analysis of ASVs across different conditions "],["07-Import_sequences_into_QIIME2.html", "Chapter 7 Import sequences into QIIME2", " Chapter 7 Import sequences into QIIME2 The input files for the QIIME2 pipeline are two text files, (a) the ‘manifest’ file and (b) the ‘metadata.file.txt.’ The ‘manifest file’ is a file listing the absolute path for the sequence files. The head of the manifest file we are going to use, is: head –n 7 PairedEndFastqManifestPhred33.csv sample-id,absolute-filepath,direction 1K1E,/pub39/tea/luca/Metagenetics_2019/RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz,forward 1K1E,/pub39/tea/luca/Metagenetics_2019/RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R2_001.fastq.gz,reverse 1K1MB,/pub39/tea/luca/Metagenetics_2019/RawReads/1K1MB_CGAGGCTG-GTAAGGAG_L001_R1_001.fastq.gz,forward 1K1MB,/pub39/tea/luca/Metagenetics_2019/RawReads/1K1MB_CGAGGCTG-GTAAGGAG_L001_R2_001.fastq.gz,reverse 1K2E,/pub39/tea/luca/Metagenetics_2019/RawReads/1K2E_AGGCAGAA-GTAAGGAG_L001_R1_001.fastq.gz,forward 1K2E,/pub39/tea/luca/Metagenetics_2019/RawReads/1K2E_AGGCAGAA-GTAAGGAG_L001_R2_001.fastq.gz,reverse In the manifest, each filed is separated by a comma ‘,’ character. The first column represents the identifier for the sample that will be used everywhere in the following analysis. The second column is the full path for the sequence file, and the third column is the orientation for the sequences in the file. If you wish to perform the pairing within DADA2, each sample will be represented by two lines: for R1 and R2. Please note, before starting the import step you have to edit the manifest file and the paths for the sequence files to match the actual path from your home folder. An example /pub39/tea/luca/Metagenetics_2019/RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz Should become (where XXX is equal to the number in your username): /pub39/tea/nscXXX/Metagenetics/RawReads/1K1E_AAGAGGCA-GTAAGGAG_L001_R1_001.fastq.gz The ‘metadata.file.txt,’ is a text table (each field separated by a ‘TAB’ character) listing all the information for each sample. less metadata.file.txt Results: sample-id BarcodeSequence Floor Location Place #q2:types categorical numeric categorical categorical K2 CTCTCTAC-ACTGCATA 1 StudentCorridor Entrance T CAGAGAGG-ACTGCATA 1 StudentHome Entrance 1K1E AAGAGGCA-GTAAGGAG 1 Corridor Entrance 1K1MB CGAGGCTG-GTAAGGAG 1 Corridor MainBuilding 1K2E AGGCAGAA-GTAAGGAG 1 Corridor Entrance 1K2M CGTACTAG-GTAAGGAG 1 Corridor MainBuilding In this file, you may want to include as much information as you can on the data, please note that if a column contains only numbers QIIME2 scripts will consider it as numerical, such as days, depths or weights (as opposed to categorical such as sex, location or barcodes). To force QIIME2 to interpret the column as you want, it is possible to specify the type of value in the second line of the file, as in this example. To run QIIME2’s commands we first need to activate it: source ~luca/Metagenetics_2019/qiime2_env.sh That will be the same as running the command source activate qiime2-2019.1 in your own installation. Next run: source tab-qiime Please, remember to run the 2 above commands on any new terminal window (or bash shell) you are going to open for the practical. When running the commands/scripts marked in red, please ensure you are in “Metagenetics” directory. First, we will load all the read pairs into an artifact. qiime tools import --type &#39;SampleData[PairedEndSequencesWithQuality]&#39; \\ --input-path PairedEndFastqManifestPhred33.csv \\ --output-path paired-end-demux.qza \\ --input-format PairedEndFastqManifestPhred33 This will use the information contained in the ‘manifest file’ to create the ‘paired-end-demux.qza,’ the name refers to the fact that samples in here are already demultiplexed (will takes approx. 1 min). To visualise the samples loaded, the following command will create a visualisation artifact associated to the main sample artifact (approx. 30 sec). qiime demux summarize --i-data paired-end-demux.qza \\ --o-visualization paired-end-demux.qzv This next step is important! Make sure to open a new terminal and open chrome in it. For the rest of the day keep this terminal and chrome open (To open a new terminal look at page 11). Opening and closing chrome multiple times has proven to cause issues in past workshops. To open the browser ‘chrome,’ run: chrome.sh Then: Type the following web-site: ‘view.qiime2.org’ Click on ‘Drag and drop or click here’ panel You can browse now to find and select the file ‘paired-end-demux.qzv’ Questions: Are the sequences evenly distributed across samples? Which sample has the lowest number of sequences? Is there any sample with a low final number of sequences? Are there any samples that can be excluded? What is the average sequence count per sample? How is the overall quality for the sequences? "],["08-Trim_PCR_sequences.html", "Chapter 8 Trim the PCR primer sequences", " Chapter 8 Trim the PCR primer sequences Reads are paired-end (R1 and R2) and may overlap in the middle, depending on the size of the sequenced amplicon and the size of the paired reads. Our sequencing data is of the 16S rRNA V4 region (length: ~250bp). Therefore, our 250bp x 2 paired end reads should overlap. If R1 and R2 overlap, we can use this to reconstruct the V4 region by aligning and merging the forward and reverse reads of each pair. We will use the “cutadapt” (Martin, 2011) tool to remove the PCR primer sequences from R1 and R2 (approx. 5 min). qiime cutadapt trim-paired --i-demultiplexed-sequences paired-end-demux.qza # Forward primer --p-front-f NNNNNGTGCCAGCMGCCGCGGTAA \\ # Reverse primer --p-front-r GGACTACHVGGGTWTCTAAT \\ --o-trimmed-sequences paired-end-demux.trim.qza To visualise the trimmed samples, the following command will create a visualisation artifact associated with the main sample artefact (approx. 2 mins). qiime demux summarize --i-data paired-end-demux.trim.qza \\ --o-visualization paired-end-demux.trim.qzv If you are working with ITS region, to trim off the conserved regions from the sequences you can use the ‘q2-itxpress’ plug in. To install and use this plug-in, please see its specific manual: https://library.qiime2.org/plugins/q2-itsxpress/8/ Depending on your experimental design, you may have to perform the trimming of the PCR primer, sequencing adapters and/or using the conserved region using the ‘itsxpress’ trimming only. Questions: Are the sequences evenly distributed across samples? Which sample has the lowest number of sequences? Are there any samples that can be excluded? What is the average sequence count per sample? How is the oveerall quality for the sequences? Which truncating lengths would you chose for R1 and R2? "],["09-ASV_identification.html", "Chapter 9 De-novo amplicon sequence variants identification", " Chapter 9 De-novo amplicon sequence variants identification We will use DADA2 to identify the amplicon sequence variants (ASVs) among all the samples. To perform the variant sequence identification step with DADA2, the command is (don’t run this command, see below command): qiime dada2 denoise-paired \\ --i-demultiplexed-seqs paired-end-demux.trim.qza \\ # Truncates R1 sequences after the 220 nt length --p-trunc-len-f 220 \\ # Truncates R2 sequences after the 220 nt length --p-trunc-len-r 220 \\ # Object containing the identified variants --o-representative-sequences rep-seqs-dada2.qza \\ # Object containing abundance table for the identified variants --o-table table-dada2.qza \\ --o-denoising-stats dada2-stats.qza \\ --verbose This step will take a long time, so stop the command (ctrl+c) and copy the final output files, which have been previously made, to your current directory: cp ~luca/Metagenetics_2019/table-dada2.qza . cp ~luca/Metagenetics_2019/rep-seqs-dada2.qza . cp ~luca/Metagenetics_2019/dada2-stats.qza . The rep-seqs-dada2.qza artifact contains the identified sequence variants and the tabledada2.qza artifact contains their abundance data. The dada2-stats.qza artifact summarises the statistics after the main denoising steps. This may be one of the longest steps of the whole pipeline. The running time is proportional to the complexity of the sequences (how many ASVs are in the dataset) and to the quality of the sequences (how many errors are present). If in your one of your future projects this step is taking too long, you may try to use ‘deblur’ to de-noise your data (after joining the reads with vsearch), which is generally faster. In the case of a marker gene with very variable amplicon sequence length, as in the case of ITS amplicon sequencing, a possible alternative denoising strategy is to disable the filtering by truncation length using the options: --p-trunc-len-f 0 and --p-trunc-len-r 0. To exclude the low quality tails the --p-trunc-q 20 option is now required, this option will trim all the sequences after the first base with quality below ‘20’ (this may be very stringent, so you may want to try with lower values as well). A further possibility may be to use only either the forward or reverse read file, for this the qiime dada2 denoise-single should be use instead the above dada2 command. To visualise the result, run: qiime feature-table summarize --i-table table-dada2.qza \\ --o-visualization table-dada2.qzv \\ --m-sample-metadata-file metadata.file.txt And load the obtained table-dada2.qzv into the ‘view.qiime2.org’ website. qiime metadata tabulate --m-input dada2-stats.qza \\ --o-visualization dada2-stats.qzv And load the obtained ‘dada2-stats.qzv’ into the ‘view.qiime2.org’ website. Questions: In which denoising step were most of the sequences lost? Are enough sequences left to proceed with the analysis? How many variants (also called ‘features’) have been identified? How are the variants distributed across samples? How many sequences are ‘rare’ (represented in few samples or in low number)? "],["10-Taxonomic_assignment.html", "Chapter 10 Assign a taxonomic classification to each amplicon sequence variant", " Chapter 10 Assign a taxonomic classification to each amplicon sequence variant Now that we have defined the sequence variants in the samples, we can assign taxonomic labels to them. Here, we use the sk-learn classifier to assign taxonomy based on the Greengenes database (DeSantis et al., 2006). Greengenes is a database containing quality-controlled microbial sequence data. Greengenes 16S rDNA sequences come from a large number of species which have been formatted for use in QIIME, by clustering the sequences at a given level of similarity (here, 99%). As for OTU-picking, the more stringent the similarity threshold, the more fine-grained the taxonomic designation (i.e. there are more Greengenes OTUs defined to the species level at 99% than at 97% similarity). The classifier maps the variant sequences, defined above, to OTU representative sequences from the Greengenes set. First, we need to import the Greengenes data into QIIME2 artifact objects. qiime tools import \\ --input-path /pub39/tea/luca/Metagenetics_2019/db/gg_13_8_otus/rep_set/99_otus.fasta \\ --output-path gg-13-8.99_otus.qza \\ --type &#39;FeatureData[Sequence]&#39; qiime tools import \\ --input-path /pub39/tea/luca/Metagenetics_2019/db/gg_13_8_otus/taxonomy/99_otu_taxonomy.txt \\ --output-path gg-13-8.99.taxa.qza \\ --input-format HeaderlessTSVTaxonomyFormat \\ --type &#39;FeatureData[Taxonomy]&#39; These steps will create two objects containing the sequences and their taxonomy, respectively, and should finish in less than 2 mins. The classifier tool we are going to use requires a training step to reach its optimum performance. The training is performed on a read set extracted from Greengenes representative sequences, including only the amplified region of interest. Note: Do not run the below command for this tutorial, see below command) qiime feature-classifier extract-reads \\ --i-sequences gg-13-8.99_otus.qza \\ --p-f-primer NNNNNGTGCCAGCMGCCGCGGTAA \\ --p-r-primer GGACTACHVGGGTWTCTAAT \\ # Creating reads of 250 bp as in our case --p-trunc-len 250 \\ --o-reads gg-13-8.99.ref.seqs.qza Given that this step may require more than 14h to finish, we won’t be able to run on this occasion. Copy over premade result with the following command: cp /pub39/tea/luca/Metagenetics_2019/gg-13-8.99.ref.seqs.qza . To train the sk-learn classifier on this set of reads (approx. 25 mins): qiime feature-classifier fit-classifier-naive-bayes \\ --i-reference-reads gg-13-8.99.ref.seqs.qza \\ --i-reference-taxonomy gg-13-8.99.taxa.qza \\ --o-classifier classifier.trained.qza The command for the taxonomy assignment is (approx. 5 min): qiime feature-classifier classify-sklearn \\ --i-classifier classifier.trained.qza \\ # Default value for confidence --p-confidence 0.7 \\ --i-reads rep-seqs-dada2.qza \\ --o-classification taxonomy.sklearn.qza To visualise the taxonomy-abundance bar-chart obtained, run (approx. 1 min): qiime taxa barplot --i-table table-dada2.qza \\ --i-taxonomy taxonomy.sklearn.qza \\ --m-metadata-file metadata.file.txt \\ --o-visualization taxa-bar-plots.dada2.qzv Once you have loaded the file in the browser, you may specify the taxonomic level to look at, as well as a few sorting and colouring options. Questions: What is the most abundant taxon, at level 5, in the dataset? How do the samples compare to each other? If you have sequenced any samples with known composition (e.g. mock community), now is the time to see if they behave as expected, you may want to change some step and/or settings of what you have done so far if the composition does not match what you expect. For example, change the de-noising tool or apply more quality filters to further improve the quality of the sequence under examination. "],["11-Phylogentic_tree.html", "Chapter 11 Make a phylogenetic tree of the identified ASVs", " Chapter 11 Make a phylogenetic tree of the identified ASVs To obtain the phylogenetic tree the steps are: Alignment of the sequence variants with MAFFT Masking out the uninformative sequences with MASK Creation of the un-rooted tree with FASTTREE Creation of the rooted tree The rooted tree will be used to compute phylogenetical aware alpha- and beta-diversity metrics such as Faith’s Phylogenetical Distance (Faith’s PD) and UniFrac distances, for any marker for which this is possible (therefore excluding ITS among others). The commands are the following: qiime alignment mafft --i-sequences rep-seqs-dada2.qza \\ --o-alignment aligned-rep-seqs.qza qiime alignment mask --i-alignment aligned-rep-seqs.qza \\ --o-masked-alignment masked-aligned-rep-seqs.qza qiime phylogeny fasttree --i-alignment masked-aligned-rep-seqs.qza \\ --o-tree unrooted-tree.qza qiime phylogeny midpoint-root --i-tree unrooted-tree.qza \\ --o-rooted-tree rooted-tree.qza All these steps should finish in approx. 3 min, the final artifact for later use is ‘rooted-tree.qza’ "],["12-Rarefaction.html", "Chapter 12 Sequencing depth evaluation: rarefaction plot", " Chapter 12 Sequencing depth evaluation: rarefaction plot The diversity detected depends, to an extent, on the sampling depth (i.e. an incompletely sampled community will appear less diverse than a fully sampled community). Therefore, to compare the diversity among samples of different sizes, we need to account for this. We can do this by rarefaction, or re-sampling, from the data. Equally sized subsamples are directly comparable among different samples. In addition, if we sample progressively smaller subsamples from a sample, we draw a curve of estimated alpha diversity. The shape of this curve is informative. If the curve plateaus, then increased sampling depth will not increase the estimate of alpha diversity (the community is fully sampled). Example rarefaction curve: We can see that Series 1 plateaus at ~7,000 sequences and Series 3 plateaus at ~18,000 sequences whilst Series 2 has not started to plateau. Given an abundance table (and a phylogenetic tree for calculating phylogenetic distance), we can plot the rarefaction curve using different alpha-diversity metrics. Here, we will use diversity metircs (observed variants, Simpson, Shannon, Faith’s PD) as well as an evenness metric (Simpson’ evenness). You may want to exclude --p-metrics faith_pd for markers such as ITS. qiime diversity alpha-rarefaction --i-table table-dada2.qza \\ --i-phylogeny rooted-tree.qza \\ # Min and max depth for the plot --p-min-depth 5000 \\ --p-max-depth 130000 \\ # Evaluating diversity every 75 seqs depth --p-steps 75 \\ # Using average from 55 iterations for the diversity count --p-iterations 55 \\ --m-metadata-file metadata.file.txt \\ --p-metrics simpson_e \\ --p-metrics simpson \\ --p-metrics shannon \\ --p-metrics observed_otus \\ --p-metrics faith_pd \\ --o-visualization rarefaction-curve.qzv The command will take approx. 10 min; the result is a visualisation artifact. From the loaded file, you can select the metric to visualize as well as the grouping (there is one non-numerical column in the metadata file). The visualization will have two plots. The top plot is an alpha rarefaction plot and is primarily used to determine if the richness of the samples has been fully observed or sequenced. If the lines in the plot appear to “level out” (i.e., approach a slope of zero) at some sampling depth along the xaxis, that suggests that collecting additional sequences beyond that sampling depth would not likely result in the observation of additional features. If the lines in a plot don’t level out, this may be because the richness of the samples hasn’t been fully observed yet (because too few sequences were collected), or it could be an indicator that a lot of sequencing errors remain in the data (which is being mistaken for novel diversity). The bottom plot in this visualization is important when grouping samples by metadata. It illustrates the number of samples that remain in each group when the feature table is rarefied to each sampling depth. If a given sampling depth (depth D) is larger than the total frequency of sample S (i.e., the number of sequences that were obtained for sample S), it is not possible to compute the diversity metric for sample S at sampling depth D. If many of the samples in a group have lower total frequencies than D, the average diversity presented for that group at D in the top plot will be unreliable because it will have been computed on relatively few samples. When grouping samples by metadata, it is therefore essential to look at the bottom plot to ensure that the data presented in the top plot is reliable. Choose a rarefaction threshold for the normalisation step, is ultimately identifying the best tradeoff between losing sequencing depth within few samples or loosing entire samples. The best choice usually depends on the experimental design, if you have sample replicates you may lose a few of these without losing statistical power for the analysis, if not it may be choosing a lower threshold (and therefore loosing sequencing for the best sequenced samples you have …) Questions: Are any samples not fully sequenced? Choose a sampling depth (rarefaction threshold) to use for the alpha- and beta-diversity analysis, you can discuss with a class-mate. "],["13-Sequencing_controls_evaluation.html", "Chapter 13 Sequencing controls evaluation: beta-diversity without normalisation", " Chapter 13 Sequencing controls evaluation: beta-diversity without normalisation The current protocols for metagenetic experiments strongly suggest to always include positive and negative controls for any stage of the lab processing of the samples (including the sequencing). It is therefore likely that in your design you will have negative controls (to explore the microbiome derived by the kits used, the so-called ‘kit-ome’) and positive controls (mock or known communities, to investigate biases from the lab protocols or the bioinformatics pipeline). To investigate if the controls (especially the negatives) show contaminations and or suspicious similarity with the samples under investigation, it is a good practice to investigate beta-diversities before proceeding with the rarefaction step. That is because the rarefaction will probably exclude most of the negative controls containing not as many reads as the samples in analysis. In the experimental design used for this practical there are no controls. However, it may be good to look at the diversity before rarefaction to compare with the same after rarefaction. The following commands are used to obtain the Principal Coordinate Analysis (PCoA) for the beta-diversity using the ‘bray-curtis’ distance. qiime diversity beta \\ --i-table table-dada2.qza \\ --p-metric braycurtis \\ --o-distance-matrix dada2.braycurtis.notNorm.diversity.qza qiime diversity pcoa \\ --i-distance-matrix dada2.braycurtis.notNorm.diversity.qza \\ --o-pcoa dada2.braycurtis.notNorm.diversity.pcoa.qza qiime emperor plot \\ --i-pcoa dada2.braycurtis.notNorm.diversity.pcoa.qza \\ --m-metadata-file metadata.file.txt \\ --o-visualization dada2.braycurtis.notNorm.diversity.pcoa.qzv These steps will take approx. 2 min. The final dada2.braycurtis.notNorm.diversity.pcoa.qzv artifact contains the first 3 axes for the PCoA analysis. It is possible to colour the samples by each metadata category group, to highlight if a specific metadata may have an effect on the diversity. "],["14-Diversity_analysis.html", "Chapter 14 Diversity analysis", " Chapter 14 Diversity analysis "],["15-Differential_abundance.html", "Chapter 15 Differential abundance analysis", " Chapter 15 Differential abundance analysis "],["16-Final_consideration.html", "Chapter 16 Final consideration", " Chapter 16 Final consideration "],["17-Resources.html", "Chapter 17 Resources", " Chapter 17 Resources "],["18-Appendix.html", "Chapter 18 Appendix", " Chapter 18 Appendix "]]
